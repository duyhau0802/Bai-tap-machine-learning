{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5yvwVzQ_sVi"
      },
      "source": [
        "# Trains a ResNet on the CIFAR10 dataset.\n",
        "### Dr. Tirthajyoti Sarkar, Fremont, CA\n",
        "\n",
        "* **ResNet paper 1**: https://arxiv.org/pdf/1512.03385.pdf (**a**)\n",
        "* **ResNet paper 2**: https://arxiv.org/pdf/1603.05027.pdf (**b**)\n",
        "\n",
        "### About CIFAR-10 dataset\n",
        "\n",
        "Website: https://www.cs.toronto.edu/~kriz/cifar.html\n",
        "\n",
        "The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n",
        "\n",
        "The dataset is divided into five training batches and one test batch, each with 10000 images. The test batch contains exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pDogiLzv_sVn"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
        "from keras.layers import AveragePooling2D, Input, Flatten\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "from keras.datasets import cifar10\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oG02k0H-_sVp"
      },
      "source": [
        "### Training parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4Xi7WCNE_sVq"
      },
      "outputs": [],
      "source": [
        "data_augmentation = True\n",
        "num_classes = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnhYIrl7_sVq"
      },
      "source": [
        "### Subtracting pixel mean improves accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NPQRefh6_sVq"
      },
      "outputs": [],
      "source": [
        "subtract_pixel_mean = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNajORBv_sVr"
      },
      "source": [
        "### How many layers? Depends on the model version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BY9uugpZ_sVr"
      },
      "outputs": [],
      "source": [
        "def model_depth(version,n=3):\n",
        "    \"\"\"\n",
        "    Computes depth from supplied model parameter n\n",
        "    \"\"\"\n",
        "    if version == 1:\n",
        "        depth = n * 6 + 2\n",
        "    elif version == 2:\n",
        "        depth = n * 9 + 2\n",
        "    return depth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2cjLiPjf_sVs"
      },
      "outputs": [],
      "source": [
        "def model_type(version,n):\n",
        "    # Model name, depth and version\n",
        "    model_type = 'ResNet%dv%d' % (model_depth(version,n), version)\n",
        "    return model_type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bfmxpct_sVs",
        "outputId": "5e8428ff-af07-4adb-cd47-15572b3e606a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet29v2\n"
          ]
        }
      ],
      "source": [
        "model_t = model_type(2,3)\n",
        "print(model_t)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psfqcRXV_sVt"
      },
      "source": [
        "### Function to show any data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "iQJmRaa0_sVt"
      },
      "outputs": [],
      "source": [
        "def show_data(sample):\n",
        "    \"\"\"\n",
        "    Shows the given sample data as an image\n",
        "    \"\"\"\n",
        "    import matplotlib.pyplot as plt\n",
        "    plt.imshow(sample)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n61JOGnI_sVt"
      },
      "source": [
        "### Load the CIFAR10 data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enu_PNOj_sVu",
        "outputId": "722c579a-182d-4644-c11e-a46945f8820e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 2s 0us/step\n"
          ]
        }
      ],
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "_lxROSum_sVv",
        "outputId": "44aa98ed-6213-46f6-b02d-429e2734e349"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAArMUlEQVR4nO3de3DU533v8c/uSruSkLRCgG5GYC4OxMGQE2oTjRNKQOWSDgdiztROMlOceuyxI3xq0zQJncSO3XbkOHMcJxmCz0xTmMwJJnHH2MeeCa6NI3GSACkKHGKnUYGIgC0kLq4uSGi12v2dP3ysVubi5yv045HE+zWzMyB9efT89rerDyvtfjYSBEEgAACusajvDQAArk8EEADACwIIAOAFAQQA8IIAAgB4QQABALwggAAAXhBAAAAvcnxv4P2y2axaW1tVVFSkSCTiezsAAKMgCNTd3a2qqipFo5d/nDPqAqi1tVXV1dW+twEAuEonT57U1KlTL/v50AJo8+bN+ta3vqW2tjYtWLBA3/ve93Tbbbd94L8rKiqSJG187DEl8vKcvlYiN9d5X7nxuPOsJMWi7ldRJGL7iWY2k3Ge7e/vN62dTrvPZ9Jp29rGvVj2PmC4TqR3HzG7CgyzkhS5wv/cLpo1Plq37NvM2K5l2UvGeH7ShttWxnidWFrErNe35b4p2a4X614sxxlms1osFnOeTaf79fJPfjz4/fxyQgmgH//4x9q4caOeeeYZLVq0SE8//bRWrFih5uZmlZWVXfHfvndHTuTlKc81gAyhEmYARY0BZLnRRg0nX7LdWDLGta/0kPpSLN/IYwMDprUtd2brHd9ynKMpgKzfhMIMIMu5t64dZgBZ9xIlgC7pg+4XoTwJ4amnntK9996rL3zhC7r55pv1zDPPqKCgQP/4j/8YxpcDAIxBIx5A/f39ampqUm1t7X98kWhUtbW12rt370XzqVRKXV1dQy4AgPFvxAPo7NmzymQyKi8vH/Lx8vJytbW1XTRfX1+vZDI5eOEJCABwffD+OqBNmzaps7Nz8HLy5EnfWwIAXAMj/iSEyZMnKxaLqb29fcjH29vbVVFRcdF8IpFQIpEY6W0AAEa5EX8EFI/HtXDhQu3evXvwY9lsVrt371ZNTc1IfzkAwBgVytOwN27cqPXr1+uP/uiPdNttt+npp59WT0+PvvCFL4Tx5QAAY1AoAXTnnXfqzJkzeuSRR9TW1qaPfvSj2rVr10VPTAAAXL9Ca0LYsGGDNmzYMOx/3/nv/66+hNsLUXNz3A8j19CaIEnRmOWFqLYXamUDwwsAjS/QHDDMZwdsTQiWtaXR8yrxMLsFrS/Ss76YN8zjtKwdNa6dY7hvhrlv6+3KuhfLvLWRIxvii0stLLdZ12P0/iw4AMD1iQACAHhBAAEAvCCAAABeEEAAAC8IIACAFwQQAMALAggA4AUBBADwggACAHgRWhXP1Trf0aX+RMppNifXUMWTY6viiRmqeCIRW55H5F7fYantkaRMxlDFk3WvypHs7ztvrUGxsFSghFmvEmbNj3V96/mx1gKZhHi9WG5XYZ57yXYdhlk3FSZTFY/jnnkEBADwggACAHhBAAEAvCCAAABeEEAAAC8IIACAFwQQAMALAggA4AUBBADwggACAHhBAAEAvBi1XXDdnV3KjcedZk1dcLnGLrhoeF1wpg4uYx1UIPe+qSBiXNzaq2WYtfaShdpjFqIwu+PMvWdhrj1KjtPapzZa9i3Z9h5mb5zlvhaNuh3j2Lz3AgDGPAIIAOAFAQQA8IIAAgB4QQABALwggAAAXhBAAAAvCCAAgBcEEADACwIIAODFqK3i6entUW6632k2JxZiFY9h7Wg0ZlrbUm1hrgYx9d/YlrbW38RihuslzCoRawVKmDU/1qYXw94j1sUNa8fGaKVNNuteTTUcYdblWPYe5vVtquJxrCXjERAAwAsCCADgBQEEAPCCAAIAeEEAAQC8IIAAAF4QQAAALwggAIAXBBAAwAsCCADgBQEEAPBi1HbB9fellM24dSBlczLO61o7oWI5A86zUUvnmdz7kiSZu8MsvU2mrjYNoyPN0n1l3ItpG8Z9B4bbimX23b3YjjMSNXTBWW5XkhQY9p613RAjgWXfpqVNAssxyt7XNlrWDrMLztR3J7dZHgEBALwY8QD6xje+oUgkMuQyd+7ckf4yAIAxLpQfwX3kIx/Ra6+99h9fJGfU/qQPAOBJKMmQk5OjioqKMJYGAIwTofwO6MiRI6qqqtLMmTP1+c9/XidOnLjsbCqVUldX15ALAGD8G/EAWrRokbZt26Zdu3Zpy5Ytamlp0Sc/+Ul1d3dfcr6+vl7JZHLwUl1dPdJbAgCMQpEgzOcESuro6ND06dP11FNP6Z577rno86lUSqlUavDvXV1dqq6u1pIVn1aO49tn5xp+x+S65ntiOe5Pl71enoYd5ltyW/dimbe/Hbv72ubfcxpuV5IUiY382yG/x/QUZeM7WwcZ928vmYz7yyms85mM+8spJCmbte3F8vIO60tBLN+iw3watkV/f0r/638+o87OThUXF192LvRnB5SUlOhDH/qQjh49esnPJxIJJRKJsLcBABhlQn8d0Pnz53Xs2DFVVlaG/aUAAGPIiAfQl770JTU2Nur48eP65S9/qc985jOKxWL67Gc/O9JfCgAwho34j+Deeustffazn9W5c+c0ZcoUfeITn9C+ffs0ZcoU0zrpgbRjmYOxIsL4G6+M4WfB5t8BGX6XYv29i2XeXE8UYl1OmML8+bj1/FgrbaKGvQfREGtnrL8DMt03bXdOy3w2a1vbep+wzId7nMYTFJKMY43aiAfQjh07RnpJAMA4RBccAMALAggA4AUBBADwggACAHhBAAEAvCCAAABeEEAAAC8IIACAFwQQAMALAggA4EXob8cwXOn0gHNvW5h9U7HA/SqKhtipZu0xC/P9gEZTl1WY75ViuQ6t72VjbqWz3MaNx2m6/xirxrKOnWBSuO8HZH9/n7H5fkBhdsFZ7j+ZAbf3X+IREADACwIIAOAFAQQA8IIAAgB4QQABALwggAAAXhBAAAAvCCAAgBcEEADACwIIAODFqK3iGUinnSsowqziyRrmo1lbnltqM8KskbHWd4Q5H2ZNieU6sc5bb1fW2qZoxnL+jVU8hr0YD1NZw7z13A841r28u/bYreIJs14nLOl02mmOR0AAAC8IIACAFwQQAMALAggA4AUBBADwggACAHhBAAEAvCCAAABeEEAAAC8IIACAFwQQAMCLUdsFl06nnXvYLF1J1s6ujKETKhqLmdaOGebD7DHLZGy9V7Ec23HmZN1vZtbeK8veLd1hkhSPx51nE4mEae2Y8Tq3dAFaewMt9whrF9xAxv18Ws+P5dxbu92CYPT0HY6WLjjL9850ut9pjkdAAAAvCCAAgBcEEADACwIIAOAFAQQA8IIAAgB4QQABALwggAAAXhBAAAAvCCAAgBcEEADAi1HbBTeQGXDuqAqzC87SqRYx9rXFYu7zlt44SYpEDGtHjR12ObabTSbq3sMVidp6zAqLCpxnSyeWmNbOz8tzH87ablfW85ljuM6t3X79/W69XZLUn06b1k4PuK+dSbnPSu/2RTrPZmw9c9b2Ncv3Fev3oMDSBWftAbSW+zlyPTc8AgIAeGEOoD179mj16tWqqqpSJBLRCy+8MOTzQRDokUceUWVlpfLz81VbW6sjR46M1H4BAOOEOYB6enq0YMECbd68+ZKff/LJJ/Xd735XzzzzjPbv368JEyZoxYoV6uvru+rNAgDGD/PvgFatWqVVq1Zd8nNBEOjpp5/W1772Na1Zs0aS9MMf/lDl5eV64YUXdNddd13dbgEA48aI/g6opaVFbW1tqq2tHfxYMpnUokWLtHfv3kv+m1Qqpa6uriEXAMD4N6IB1NbWJkkqLy8f8vHy8vLBz71ffX29ksnk4KW6unoktwQAGKW8Pwtu06ZN6uzsHLycPHnS95YAANfAiAZQRUWFJKm9vX3Ix9vb2wc/936JRELFxcVDLgCA8W9EA2jGjBmqqKjQ7t27Bz/W1dWl/fv3q6amZiS/FABgjDM/C+78+fM6evTo4N9bWlp06NAhlZaWatq0aXrooYf0d3/3d7rppps0Y8YMff3rX1dVVZXWrl07kvsGAIxx5gA6cOCAPvWpTw3+fePGjZKk9evXa9u2bfryl7+snp4e3Xfffero6NAnPvEJ7dq1S3mWWhNJAwMZubZEWGpNrNUTEUO1hWVWstX8mKt4DA9uLbU9km3fkm3vEwonmNZOliSdZ0tKbD/eLZs02Xl2Qr57JZD07uvpLM6cOeM8e7b90k/4uZxTl3mC0KVY9z0wYKvAsSgsLHSezZ/gPitJ/Zb6G0nZkCptJGMVzygx4FjFYw6gJUuWXPGbeCQS0eOPP67HH3/cujQA4Dri/VlwAIDrEwEEAPCCAAIAeEEAAQC8IIAAAF4QQAAALwggAIAXBBAAwAsCCADgBQEEAPDCXMVzrWSzWXO3mgtrF5yFdb+WvVi74BLxhPOstacvkXBf2yqRyDXNt7a2Os8e+bd/M609sci9O+5jH/0vprVnzZplmv/973/vPPtvR46Y1r5w4YLzbH9/v2ntVCrlPGu9XaVSfc6zpca+w3h+vmn+Qm+vYdr6fcK9C8763W3kv8O+y7UDkEdAAAAvCCAAgBcEEADACwIIAOAFAQQA8IIAAgB4QQABALwggAAAXhBAAAAvCCAAgBejtorHIpt1r6oIc21rFU8ymXSevfHGG01rz5w503l24sQS09rt7e2m+TfffNN5tnRSqWntgYx7NUzaWCNzzFB/84eW46a1/+zP/sw0v3r1aufZ0lLbdXjo0CHn2e7ubtPabW1tzrPRqO3/w5ZWrc6ODtPaUwxVVpKUn3Cvszp39pxpbWsNl0041WQZqngAAKMZAQQA8IIAAgB4QQABALwggAAAXhBAAAAvCCAAgBcEEADACwIIAOAFAQQA8IIAAgB4MWq74HJzc0PpQLKuWV5e7jx70003mdaeNWuW82xhYaFp7d7eHufZ8z22fq+Tb50wzZ9754zz7JSySaa1Ldf5DVU3mNY+HD3oPHvq7VbT2g0NDab5W2+91Xn2T//0T01rT58+3Xn24EH360SS4vG48+zbb79tWvvChQvOs7m5tm63IHvaND97tvt9ORiwdVeeOeO+l0gkxMcUhqrLTIYuOADAKEYAAQC8IIAAAF4QQAAALwggAIAXBBAAwAsCCADgBQEEAPCCAAIAeEEAAQC8GLVVPHmJhGI5btvLZt2rLayVNpNKS51n582bZ1r7hhvcq2GiMdv/FVyrMCSpq7PDtHZ+fp5pfsGC+c6z8YStMmXKlCnOswPptGntd864Vwj1nD9vWru4qMg0X15e5jxbZFx7/vxbnGfLytz3IUk3zrjRefZ4y3HT2j3n3eum8vJst9lYzL1CSLLdPyeWTDStPZBKOc92dttqtSIR934dy6zrYxseAQEAvCCAAABemANoz549Wr16taqqqhSJRPTCCy8M+fzdd9+tSCQy5LJy5cqR2i8AYJwwB1BPT48WLFigzZs3X3Zm5cqVOnXq1ODl2WefvapNAgDGH/OTEFatWqVVq1ZdcSaRSKiiomLYmwIAjH+h/A6ooaFBZWVlmjNnjh544AGdO3fusrOpVEpdXV1DLgCA8W/EA2jlypX64Q9/qN27d+ub3/ymGhsbtWrVKmUymUvO19fXK5lMDl6qq6tHeksAgFFoxF8HdNdddw3++ZZbbtH8+fM1a9YsNTQ0aNmyZRfNb9q0SRs3bhz8e1dXFyEEANeB0J+GPXPmTE2ePFlHjx695OcTiYSKi4uHXAAA41/oAfTWW2/p3LlzqqysDPtLAQDGEPOP4M6fPz/k0UxLS4sOHTqk0tJSlZaW6rHHHtO6detUUVGhY8eO6ctf/rJmz56tFStWjOjGAQBjWyQIgsDyDxoaGvSpT33qoo+vX79eW7Zs0dq1a3Xw4EF1dHSoqqpKy5cv19/+7d+qvLzcaf2uri4lk0nddvsnlePYBWfpKEoYu8a6DX1TM2+6ybT20mVLnWfzJ0wwrV3heH1LUoGx2y0Rt12HsZyYad7ifI9799U7Zy//bMxLOdve7jybG7MdY7KwwDQ/86ZZzrNxY+9Zr6HHrrfb1nmXY7itHD9+wrT2iaPHnWe7OmzPru1Mud/vJSkSz3WeDS64d7tJ0ttHWpxnW429jlm5f/u3fJ8dGBhQ069+oc7Oziv+WsX8CGjJkiW6Uma98sor1iUBANchuuAAAF4QQAAALwggAIAXBBAAwAsCCADgBQEEAPCCAAIAeEEAAQC8IIAAAF4QQAAAL0b8/YBGSn5ewrkLzlJnV1iQb9rHxJKJzrOtb79tWrulxb3jqWRSqWntvr4+59kpkyaZ1i4pKTHNFxUWOc8WGDvSMtkB99nLvCni5cya5d6/dtNM91lJKim2Hefbba3Os6fb20xrd55278g79ps3TWtfSPU7z2Zy3fvUJEmBe/9eTq7tW11swPZ/89x89867HmOfXjDgfrstNX6fOPfOO86z0aj7deI6yyMgAIAXBBAAwAsCCADgBQEEAPCCAAIAeEEAAQC8IIAAAF4QQAAALwggAIAXBBAAwItRW8UTj8eV61jNYalYmVBYaNpHJuNe81M0wba2pbrH9bp4z4WeXufZDkMdhyQlk8nQ5ieWulcfSVJOjvv/oXp6bBUoTfv3O88+39VtWrvui/eb5pMT3StWjh/9g2ntX77+f5xnG5//36a1J02Z4jz70aWLTWuX3nCD82w05l7bI0mTcstN85mI+/eJvgL3aipJKs6b4Dx7rNW9skmSOru6nGcjkYjzrGs9Go+AAABeEEAAAC8IIACAFwQQAMALAggA4AUBBADwggACAHhBAAEAvCCAAABeEEAAAC8IIACAF6O2Cy43N9e5/8zSUZTNZk37yEvkOc+m+wdMa3e+0+E8WzzP1h+Vzrjvpaenx7S2df706dPOs4VFtj69ggL383Pi+HHT2rt373ae7U/1m9aOJ+Km+dX/dbXz7JHf/9609jsdnc6zCz72MdPaa/7bHc6z0z96i2lt0zVu+B4hSb19F0zzrW2nnGdPpI+b1u6X+/es3gvuHZCSlJMTTgTQBQcAGNUIIACAFwQQAMALAggA4AUBBADwggACAHhBAAEAvCCAAABeEEAAAC8IIACAF6O2iic/L0+5cbe6kv5+91IOa/VELOKe0dkBWxXPmXfecZ49e+aMae0PzZ3jPBuNxUxrD2Qypvm+vj7n2ZRhVpLOnTvnPHvy5EnT2tGo+7kvKCgwrd3U9GvT/LSZs5xn24y3lR5DS81n13/OtHaiyP162fd/m0xr93S71+Wk+tOmtTu6OkzznR3u85GY7f/9rWfanGcHBmz3zbjj91iraNTtRsUjIACAF6YAqq+v16233qqioiKVlZVp7dq1am5uHjLT19enuro6TZo0SYWFhVq3bp3a29tHdNMAgLHPFECNjY2qq6vTvn379OqrryqdTmv58uVD2pEffvhhvfTSS3ruuefU2Nio1tZW3XGHeyMuAOD6YPqFyK5du4b8fdu2bSorK1NTU5MWL16szs5O/eAHP9D27du1dOlSSdLWrVv14Q9/WPv27dPHP/7xkds5AGBMu6rfAXV2vvs+IqWlpZKkpqYmpdNp1dbWDs7MnTtX06ZN0969ey+5RiqVUldX15ALAGD8G3YAZbNZPfTQQ7r99ts1b948SVJbW5vi8bhKSkqGzJaXl6ut7dLP5Kivr1cymRy8VFdXD3dLAIAxZNgBVFdXpzfeeEM7duy4qg1s2rRJnZ2dgxfrU2UBAGPTsF4HtGHDBr388svas2ePpk6dOvjxiooK9ff3q6OjY8ijoPb2dlVUVFxyrUQioUQiMZxtAADGMNMjoCAItGHDBu3cuVOvv/66ZsyYMeTzCxcuVG5urnbv3j34sebmZp04cUI1NTUjs2MAwLhgegRUV1en7du368UXX1RRUdHg73WSyaTy8/OVTCZ1zz33aOPGjSotLVVxcbEefPBB1dTU8Aw4AMAQpgDasmWLJGnJkiVDPr5161bdfffdkqRvf/vbikajWrdunVKplFasWKHvf//7I7JZAMD4YQqgIAg+cCYvL0+bN2/W5s2bh70pSSosKnTuKUqn3XueLLOS1NXt/rTwjn/vMK19+jLPDLyUxtcbTGsfbznuPFtReenfz13OpEmTTPMFBROcZ7OBrcuq9/x559nUBVvPnD745j4oLy/PtHQ0auvf+/UB9560AWVNawcx9zK4kx1nTWu3HXFvQTlx4i3T2kV5hc6zVZVVprUvXOg1zVv6KC+kbLfDDsNLU2LGXsd4PNd5NhJxv52k0277oAsOAOAFAQQA8IIAAgB4QQABALwggAAAXhBAAAAvCCAAgBcEEADACwIIAOAFAQQA8GJYb8dwLRQVFTq/TUM6PeC8bqo/ZdpHOuW+dizHVoORY6jNaGttNa199rR7BUpurlvl0XsKC92rdSSptNS9umfSpFLT2kVFhr0YbieSNGXSZOfZqspK09otLS2m+fa33GtqSo3XoaW+5eCBg6a1z/f0OM+6VH39Z0lDFU/KWH8TZG17seg9736dSFKO3Ctw8gtslVCWc29o4lFO2m2YR0AAAC8IIACAFwQQAMALAggA4AUBBADwggACAHhBAAEAvCCAAABeEEAAAC8IIACAFwQQAMCLUdwFV6S8PLdeo4EB946vTCZj2kdJ8UTn2RsqbzCtPXfuHOfZCxcumNY+d+6c8+zp06dNa79z7h3TfOvblh67rGltSy9daamtIy2dTjvP9ho6zyQ59xy+p7u723k23/F+MxzdnV2m+ebfNTvP3nBDlWntG6unOc+eP3/etPYZ433i94Zuv3fesd1/brzxRufZCRMKTGtHo+6PQSyz/f25bms6rwgAwAgigAAAXhBAAAAvCCAAgBcEEADACwIIAOAFAQQA8IIAAgB4QQABALwggAAAXozaKp7ioiLl5ec7zVqqeLJZW9WLshHn0chE91lJyhj2MmCohZGkqVPda4F6jDUynZ2dpnlL9YilQujdtS2VQ+2mtWfPvsl51lLbI0lnz541zVtu49brMJVKOc/m5rpVrLzn7Dn34+zqttX8tJ46ZVjbvcpIkjo6O0zz/YbzX15eblrbcp1bz088Hneezclxj4tcx1keAQEAvCCAAABeEEAAAC8IIACAFwQQAMALAggA4AUBBADwggACAHhBAAEAvCCAAABeEEAAAC9GbRdcfkGB8kdBF1yQcZ8PgsC0tmUvQcJ2qvKzCefZggl5prWTJUWm+YqKMufZvlSfae3urvPOs9aONEu/m7ULrqOjwzTf398f2tqWLjjrbTwWiznPXrhwwbR2t6HfLSdu60grKi42zSeTSedZaxdcUZH7/a2wsNC0dl6e+33f0gWXcrwf8wgIAOCFKYDq6+t16623qqioSGVlZVq7dq2am5uHzCxZskSRSGTI5f777x/RTQMAxj5TADU2Nqqurk779u3Tq6++qnQ6reXLl19U53/vvffq1KlTg5cnn3xyRDcNABj7TL9Y2LVr15C/b9u2TWVlZWpqatLixYsHP15QUKCKioqR2SEAYFy6qt8BvffGZKWlpUM+/qMf/UiTJ0/WvHnztGnTJvX29l52jVQqpa6uriEXAMD4N+xnwWWzWT300EO6/fbbNW/evMGPf+5zn9P06dNVVVWlw4cP6ytf+Yqam5v1/PPPX3Kd+vp6PfbYY8PdBgBgjBp2ANXV1emNN97Qz3/+8yEfv++++wb/fMstt6iyslLLli3TsWPHNGvWrIvW2bRpkzZu3Dj4966uLlVXVw93WwCAMWJYAbRhwwa9/PLL2rNnj6ZOnXrF2UWLFkmSjh49eskASiQSSiTcX7MCABgfTAEUBIEefPBB7dy5Uw0NDZoxY8YH/ptDhw5JkiorK4e1QQDA+GQKoLq6Om3fvl0vvviiioqK1NbWJundVwHn5+fr2LFj2r59uz796U9r0qRJOnz4sB5++GEtXrxY8+fPD+UAAABjkymAtmzZIundF5v+Z1u3btXdd9+teDyu1157TU8//bR6enpUXV2tdevW6Wtf+9qIbRgAMD6YfwR3JdXV1WpsbLyqDb0nJyfH1D3kytoFl42498wFxrWjUfeeLHvPnGXafR+SFInYerViMfdn+8cTtrXzEm59gZJUbOz3snSqRaO2VzRY+gslXfGlDO9n6SWzikQipnnLfdj6u+CCggL32QkTTGsXFtv6Di23LetxWvraLLOSlJvrfn+znHvX804XHADACwIIAOAFAQQA8IIAAgB4QQABALwggAAAXhBAAAAvCCAAgBcEEADACwIIAODFyHfdjJBMJqNMJuM0a6k1MVfxZMJb21qvY5HNuq9tGJUkBcb/t0QM4zmGeiJJikbdq0RyE3HT2vkT3KteJpdNMa2dyVhvK+7zgfGEWqajxiqeWI77+bRWb+XE3OcjObbbbMy4l6ihbioi23VoqXmKGCuhLDsxVfFk3b538wgIAOAFAQQA8IIAAgB4QQABALwggAAAXhBAAAAvCCAAgBcEEADACwIIAOAFAQQA8IIAAgB4MWq74C709jp3pbl2xllnJVu/m7XbzbKXMHvjgsDWTWXtvAtTmNeLDN1X1u6wnFxjp1rMvVPN0tllNZrWtswbb+KSodtNkrKW9Y232cDQ1hcYuisl23VomU3TBQcAGM0IIACAFwQQAMALAggA4AUBBADwggACAHhBAAEAvCCAAABeEEAAAC8IIACAF6O2iqent1cZx8qXMOtyBgbcqy2sFTWWvVj3baopMfaUhFp/M4qEWTlkrZ2x3A6totHw/h8aVtWLdd5axRMMhLcXqzCvw7D20Z9KOc3xCAgA4AUBBADwggACAHhBAAEAvCCAAABeEEAAAC8IIACAFwQQAMALAggA4AUBBADwggACAHgxarvgUn19zrOZTCa0fVjWtnakhdmpZln6Oql2MwuzCy7M/jUrU6eade2Q9mGejxr7Do3zFmEeZ5hdcBYpuuAAAKOZKYC2bNmi+fPnq7i4WMXFxaqpqdFPf/rTwc/39fWprq5OkyZNUmFhodatW6f29vYR3zQAYOwzBdDUqVP1xBNPqKmpSQcOHNDSpUu1Zs0avfnmm5Kkhx9+WC+99JKee+45NTY2qrW1VXfccUcoGwcAjG2m3wGtXr16yN///u//Xlu2bNG+ffs0depU/eAHP9D27du1dOlSSdLWrVv14Q9/WPv27dPHP/7xkds1AGDMG/bvgDKZjHbs2KGenh7V1NSoqalJ6XRatbW1gzNz587VtGnTtHfv3suuk0ql1NXVNeQCABj/zAH0m9/8RoWFhUokErr//vu1c+dO3XzzzWpra1M8HldJScmQ+fLycrW1tV12vfr6eiWTycFLdXW1+SAAAGOPOYDmzJmjQ4cOaf/+/XrggQe0fv16/fa3vx32BjZt2qTOzs7By8mTJ4e9FgBg7DC/Digej2v27NmSpIULF+pf/uVf9J3vfEd33nmn+vv71dHRMeRRUHt7uyoqKi67XiKRUCKRsO8cADCmXfXrgLLZrFKplBYuXKjc3Fzt3r178HPNzc06ceKEampqrvbLAADGGdMjoE2bNmnVqlWaNm2auru7tX37djU0NOiVV15RMpnUPffco40bN6q0tFTFxcV68MEHVVNTwzPgAAAXMQXQ6dOn9ed//uc6deqUksmk5s+fr1deeUV/8id/Ikn69re/rWg0qnXr1imVSmnFihX6/ve/P6yN9aVSzrUfYVbxhFuX4762dR/ZrGVt09KjymipHrEK83YV5nUyZmtkjNU62RC3Yj3O0VTb5CrV3+80FwnCvCcMQ1dXl5LJpP77xoedfzdEAF2MABrdCKCrX9uEALqmUqmUvv8/nlJnZ6eKi4svOzf2jgwAMC4QQAAALwggAIAXBBAAwAsCCADgBQEEAPCCAAIAeEEAAQC8IIAAAF6Y27DD9t4rxFOplPO/oQnhEvM0IYxqY7UJQTQhXLXroQmh//9///6g2/moq+J56623eFM6ABgHTp48qalTp17286MugLLZrFpbW1VUVDTkfwpdXV2qrq7WyZMnr9gtNNZxnOPH9XCMEsc53ozEcQZBoO7ublVVVV3xEdyo+xFcNBq9YmIWFxeP65P/Ho5z/LgejlHiOMebqz3OZDL5gTNj74eLAIBxgQACAHgxZgIokUjo0UcfdX6PoLGK4xw/rodjlDjO8eZaHueoexICAOD6MGYeAQEAxhcCCADgBQEEAPCCAAIAeDFmAmjz5s268cYblZeXp0WLFulXv/qV7y2NqG984xuKRCJDLnPnzvW9rauyZ88erV69WlVVVYpEInrhhReGfD4IAj3yyCOqrKxUfn6+amtrdeTIET+bvQofdJx33333Red25cqVfjY7TPX19br11ltVVFSksrIyrV27Vs3NzUNm+vr6VFdXp0mTJqmwsFDr1q1Te3u7px0Pj8txLlmy5KLzef/993va8fBs2bJF8+fPH3yxaU1NjX76058Ofv5ancsxEUA//vGPtXHjRj366KP69a9/rQULFmjFihU6ffq0762NqI985CM6derU4OXnP/+57y1dlZ6eHi1YsECbN2++5OeffPJJffe739Uzzzyj/fv3a8KECVqxYoX6+vqu8U6vzgcdpyStXLlyyLl99tlnr+EOr15jY6Pq6uq0b98+vfrqq0qn01q+fLl6enoGZx5++GG99NJLeu6559TY2KjW1lbdcccdHndt53KcknTvvfcOOZ9PPvmkpx0Pz9SpU/XEE0+oqalJBw4c0NKlS7VmzRq9+eabkq7huQzGgNtuuy2oq6sb/HsmkwmqqqqC+vp6j7saWY8++miwYMEC39sIjaRg586dg3/PZrNBRUVF8K1vfWvwYx0dHUEikQieffZZDzscGe8/ziAIgvXr1wdr1qzxsp+wnD59OpAUNDY2BkHw7rnLzc0NnnvuucGZf/3Xfw0kBXv37vW1zav2/uMMgiD44z/+4+Av//Iv/W0qJBMnTgz+4R/+4Zqey1H/CKi/v19NTU2qra0d/Fg0GlVtba327t3rcWcj78iRI6qqqtLMmTP1+c9/XidOnPC9pdC0tLSora1tyHlNJpNatGjRuDuvktTQ0KCysjLNmTNHDzzwgM6dO+d7S1els7NTklRaWipJampqUjqdHnI+586dq2nTpo3p8/n+43zPj370I02ePFnz5s3Tpk2b1Nvb62N7IyKTyWjHjh3q6elRTU3NNT2Xo66M9P3Onj2rTCaj8vLyIR8vLy/X7373O0+7GnmLFi3Stm3bNGfOHJ06dUqPPfaYPvnJT+qNN95QUVGR7+2NuLa2Nkm65Hl973PjxcqVK3XHHXdoxowZOnbsmP7mb/5Gq1at0t69exWLxXxvzyybzeqhhx7S7bffrnnz5kl693zG43GVlJQMmR3L5/NSxylJn/vc5zR9+nRVVVXp8OHD+spXvqLm5mY9//zzHndr95vf/EY1NTXq6+tTYWGhdu7cqZtvvlmHDh26Zudy1AfQ9WLVqlWDf54/f74WLVqk6dOn6yc/+YnuuecejzvD1brrrrsG/3zLLbdo/vz5mjVrlhoaGrRs2TKPOxueuro6vfHGG2P+d5Qf5HLHed999w3++ZZbblFlZaWWLVumY8eOadasWdd6m8M2Z84cHTp0SJ2dnfqnf/onrV+/Xo2Njdd0D6P+R3CTJ09WLBa76BkY7e3tqqio8LSr8JWUlOhDH/qQjh496nsroXjv3F1v51WSZs6cqcmTJ4/Jc7thwwa9/PLL+tnPfjbkbVMqKirU39+vjo6OIfNj9Xxe7jgvZdGiRZI05s5nPB7X7NmztXDhQtXX12vBggX6zne+c03P5agPoHg8roULF2r37t2DH8tms9q9e7dqamo87ixc58+f17Fjx1RZWel7K6GYMWOGKioqhpzXrq4u7d+/f1yfV+ndd/09d+7cmDq3QRBow4YN2rlzp15//XXNmDFjyOcXLlyo3NzcIeezublZJ06cGFPn84OO81IOHTokSWPqfF5KNptVKpW6tudyRJ/SEJIdO3YEiUQi2LZtW/Db3/42uO+++4KSkpKgra3N99ZGzF/91V8FDQ0NQUtLS/CLX/wiqK2tDSZPnhycPn3a99aGrbu7Ozh48GBw8ODBQFLw1FNPBQcPHgz+8Ic/BEEQBE888URQUlISvPjii8Hhw4eDNWvWBDNmzAguXLjgeec2VzrO7u7u4Etf+lKwd+/eoKWlJXjttdeCj33sY8FNN90U9PX1+d66swceeCBIJpNBQ0NDcOrUqcFLb2/v4Mz9998fTJs2LXj99deDAwcOBDU1NUFNTY3HXdt90HEePXo0ePzxx4MDBw4ELS0twYsvvhjMnDkzWLx4seed23z1q18NGhsbg5aWluDw4cPBV7/61SASiQT//M//HATBtTuXYyKAgiAIvve97wXTpk0L4vF4cNtttwX79u3zvaURdeeddwaVlZVBPB4PbrjhhuDOO+8Mjh496ntbV+VnP/tZIOmiy/r164MgePep2F//+teD8vLyIJFIBMuWLQuam5v9bnoYrnScvb29wfLly4MpU6YEubm5wfTp04N77713zP3n6VLHJynYunXr4MyFCxeCL37xi8HEiRODgoKC4DOf+Uxw6tQpf5sehg86zhMnTgSLFy8OSktLg0QiEcyePTv467/+66Czs9Pvxo3+4i/+Ipg+fXoQj8eDKVOmBMuWLRsMnyC4dueSt2MAAHgx6n8HBAAYnwggAIAXBBAAwAsCCADgBQEEAPCCAAIAeEEAAQC8IIAAAF4QQAAALwggAIAXBBAAwAsCCADgxf8DUrfiztQ/puUAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "show_data(x_train[250])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "gxBMWWFP_sVv"
      },
      "outputs": [],
      "source": [
        "# Input image dimensions.\n",
        "input_shape = x_train.shape[1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dows4CX4_sVw",
        "outputId": "3298e7be-decd-43fb-e0b1-aad8415de2b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 32, 3)\n"
          ]
        }
      ],
      "source": [
        "print(input_shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jHkwyQ-_sVw"
      },
      "source": [
        "### Normalize data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "FGrE5Mth_sVw"
      },
      "outputs": [],
      "source": [
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tV60KUbh_sVx"
      },
      "outputs": [],
      "source": [
        "show_data(x_train[250])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7s8KCQ8_sVx"
      },
      "source": [
        "### If `subtract_pixel_mean` is enabled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "uPCP3wtB_sVx"
      },
      "outputs": [],
      "source": [
        "# If subtract pixel mean is enabled\n",
        "if subtract_pixel_mean:\n",
        "    x_train_mean = np.mean(x_train, axis=0)\n",
        "    x_train -= x_train_mean\n",
        "    x_test -= x_train_mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "007BCpIP_sVx",
        "outputId": "0d85e1b2-e82d-4cb3-ada1-4ba48d9fc7ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n",
            "y_train shape: (50000, 1)\n"
          ]
        }
      ],
      "source": [
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "print('y_train shape:', y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06lL5PAC_sVy"
      },
      "outputs": [],
      "source": [
        "show_data(x_train[250])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gRFoPU8_sVy"
      },
      "source": [
        "### Convert class vectors to binary class matrices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "-luYtiqL_sVy"
      },
      "outputs": [],
      "source": [
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flRJ9ZcF_sVy"
      },
      "source": [
        "### Function for auto-scaling learning based on epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "TNT7shKZ_sVy"
      },
      "outputs": [],
      "source": [
        "def lr_schedule(epoch):\n",
        "    \"\"\"Learning Rate Schedule\n",
        "\n",
        "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
        "    Called automatically every epoch as part of callbacks during training.\n",
        "\n",
        "    # Arguments\n",
        "        epoch (int): The number of epochs\n",
        "\n",
        "    # Returns\n",
        "        lr (float32): learning rate\n",
        "    \"\"\"\n",
        "    lr = 1e-3\n",
        "    if epoch > 180:\n",
        "        lr *= 0.5e-3\n",
        "    elif epoch > 160:\n",
        "        lr *= 1e-3\n",
        "    elif epoch > 120:\n",
        "        lr *= 1e-2\n",
        "    elif epoch > 80:\n",
        "        lr *= 1e-1\n",
        "    print('Learning rate: ', lr)\n",
        "    return lr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8uz5-Zi_sVy"
      },
      "source": [
        "### Function of a single ResNet layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "_qscy924_sVz"
      },
      "outputs": [],
      "source": [
        "def resnet_layer(inputs,\n",
        "                 num_filters=16,\n",
        "                 kernel_size=3,\n",
        "                 strides=1,\n",
        "                 activation='relu',\n",
        "                 batch_normalization=True,\n",
        "                 conv_first=True):\n",
        "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
        "\n",
        "    # Arguments\n",
        "        inputs (tensor): input tensor from input image or previous layer\n",
        "        num_filters (int): Conv2D number of filters\n",
        "        kernel_size (int): Conv2D square kernel dimensions\n",
        "        strides (int): Conv2D square stride dimensions\n",
        "        activation (string): activation name\n",
        "        batch_normalization (bool): whether to include batch normalization\n",
        "        conv_first (bool): conv-bn-activation (True) or bn-activation-conv (False)\n",
        "\n",
        "    # Returns\n",
        "        x (tensor): tensor as input to the next layer\n",
        "    \"\"\"\n",
        "    conv = Conv2D(num_filters,\n",
        "                  kernel_size=kernel_size,\n",
        "                  strides=strides,\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal',\n",
        "                  kernel_regularizer=l2(1e-4))\n",
        "\n",
        "    x = inputs\n",
        "    if conv_first:\n",
        "        x = conv(x)\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "    else:\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "        x = conv(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4hqGHab_sVz"
      },
      "source": [
        "### ResNet Version 1 model builder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "1F4Qcy37_sVz"
      },
      "outputs": [],
      "source": [
        "def resnet_v1(input_shape, depth, num_classes=10):\n",
        "    \"\"\"ResNet Version 1 Model builder [a]\n",
        "\n",
        "    Stacks of 2 x (3 x 3) Conv2D-BN-ReLU\n",
        "    Last ReLU is after the shortcut connection.\n",
        "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
        "    by a convolutional layer with strides=2, while the number of filters is\n",
        "    doubled. Within each stage, the layers have the same number filters and the\n",
        "    same number of filters.\n",
        "    Features maps sizes:\n",
        "    stage 0: 32x32, 16\n",
        "    stage 1: 16x16, 32\n",
        "    stage 2:  8x8,  64\n",
        "    The Number of parameters is approx the same as Table 6 of [a]:\n",
        "    ResNet20 0.27M\n",
        "    ResNet32 0.46M\n",
        "    ResNet44 0.66M\n",
        "    ResNet56 0.85M\n",
        "    ResNet110 1.7M\n",
        "\n",
        "    # Arguments\n",
        "        input_shape (tensor): shape of input image tensor\n",
        "        depth (int): number of core convolutional layers\n",
        "        num_classes (int): number of classes (CIFAR10 has 10)\n",
        "\n",
        "    # Returns\n",
        "        model (Model): Keras model instance\n",
        "    \"\"\"\n",
        "    if (depth - 2) % 6 != 0:\n",
        "        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\n",
        "    # Start model definition.\n",
        "    num_filters = 16\n",
        "    num_res_blocks = int((depth - 2) / 6)\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = resnet_layer(inputs=inputs)\n",
        "    # Instantiate the stack of residual units\n",
        "    for stack in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            strides = 1\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
        "                strides = 2  # downsample\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters,\n",
        "                             strides=strides)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters,\n",
        "                             activation=None)\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
        "                # linear projection residual shortcut connection to match\n",
        "                # changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = keras.layers.add([x, y])\n",
        "            x = Activation('relu')(x)\n",
        "        num_filters *= 2\n",
        "\n",
        "    # Add classifier on top.\n",
        "    # v1 does not use BN after last shortcut connection-ReLU\n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    y = Flatten()(x)\n",
        "    outputs = Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(y)\n",
        "\n",
        "    # Instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPNNaY6b_sVz"
      },
      "source": [
        "### ResNet Version 2 model builder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "31FXPrpw_sVz"
      },
      "outputs": [],
      "source": [
        "def resnet_v2(input_shape, depth, num_classes=10):\n",
        "    \"\"\"ResNet Version 2 Model builder [b]\n",
        "\n",
        "    Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or also known as\n",
        "    bottleneck layer\n",
        "    First shortcut connection per layer is 1 x 1 Conv2D.\n",
        "    Second and onwards shortcut connection is identity.\n",
        "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
        "    by a convolutional layer with strides=2, while the number of filter maps is\n",
        "    doubled. Within each stage, the layers have the same number filters and the\n",
        "    same filter map sizes.\n",
        "    Features maps sizes:\n",
        "    conv1  : 32x32,  16\n",
        "    stage 0: 32x32,  64\n",
        "    stage 1: 16x16, 128\n",
        "    stage 2:  8x8,  256\n",
        "\n",
        "    # Arguments\n",
        "        input_shape (tensor): shape of input image tensor\n",
        "        depth (int): number of core convolutional layers\n",
        "        num_classes (int): number of classes (CIFAR10 has 10)\n",
        "\n",
        "    # Returns\n",
        "        model (Model): Keras model instance\n",
        "    \"\"\"\n",
        "    if (depth - 2) % 9 != 0:\n",
        "        raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\n",
        "    # Start model definition.\n",
        "    num_filters_in = 16\n",
        "    num_res_blocks = int((depth - 2) / 9)\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\n",
        "    x = resnet_layer(inputs=inputs,\n",
        "                     num_filters=num_filters_in,\n",
        "                     conv_first=True)\n",
        "\n",
        "    # Instantiate the stack of residual units\n",
        "    for stage in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            activation = 'relu'\n",
        "            batch_normalization = True\n",
        "            strides = 1\n",
        "            if stage == 0:\n",
        "                num_filters_out = num_filters_in * 4\n",
        "                if res_block == 0:  # first layer and first stage\n",
        "                    activation = None\n",
        "                    batch_normalization = False\n",
        "            else:\n",
        "                num_filters_out = num_filters_in * 2\n",
        "                if res_block == 0:  # first layer but not first stage\n",
        "                    strides = 2    # downsample\n",
        "\n",
        "            # bottleneck residual unit\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters_in,\n",
        "                             kernel_size=1,\n",
        "                             strides=strides,\n",
        "                             activation=activation,\n",
        "                             batch_normalization=batch_normalization,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_in,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_out,\n",
        "                             kernel_size=1,\n",
        "                             conv_first=False)\n",
        "            if res_block == 0:\n",
        "                # linear projection residual shortcut connection to match\n",
        "                # changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters_out,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = keras.layers.add([x, y])\n",
        "\n",
        "        num_filters_in = num_filters_out\n",
        "\n",
        "    # Add classifier on top.\n",
        "    # v2 has BN-ReLU before Pooling\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    y = Flatten()(x)\n",
        "    outputs = Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(y)\n",
        "\n",
        "    # Instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5Qhe4E__sV0"
      },
      "source": [
        "### Choose model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "U9k-6MHj_sV0"
      },
      "outputs": [],
      "source": [
        "def choose_model(version=1):\n",
        "    \"\"\"\n",
        "    Chooses the model based on version\n",
        "\n",
        "    # Argument:\n",
        "        An (int) version number (1 or 2)\n",
        "    # Returns:\n",
        "        keras model\n",
        "    \"\"\"\n",
        "    if version == 2:\n",
        "        model = resnet_v2(input_shape=input_shape, depth=depth)\n",
        "    else:\n",
        "        model = resnet_v1(input_shape=input_shape, depth=depth)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpqCrCNg_sV0"
      },
      "source": [
        "### Choose version, parameter `n`, compile, and show summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "f6OtNzaY_sV0"
      },
      "outputs": [],
      "source": [
        "version = 1\n",
        "n = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "bqBZyQZV_sV0"
      },
      "outputs": [],
      "source": [
        "depth = model_depth(version=version,n=n)\n",
        "model = choose_model(version)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kEOwc0N_sV5",
        "outputId": "a8443775-8fc9-42c7-cad1-3a2a3f045bb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet20v1\n"
          ]
        }
      ],
      "source": [
        "print(model_type(version,n))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkFrCsP-_sV5",
        "outputId": "1976da18-38c2-4e76-b1e6-9ad797f11d25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate:  0.001\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 32, 32, 3)]          0         []                            \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)             (None, 32, 32, 16)           448       ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization (Batch  (None, 32, 32, 16)           64        ['conv2d[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation (Activation)     (None, 32, 32, 16)           0         ['batch_normalization[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)           (None, 32, 32, 16)           2320      ['activation[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_1 (Bat  (None, 32, 32, 16)           64        ['conv2d_1[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_1 (Activation)   (None, 32, 32, 16)           0         ['batch_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)           (None, 32, 32, 16)           2320      ['activation_1[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_2 (Bat  (None, 32, 32, 16)           64        ['conv2d_2[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " add (Add)                   (None, 32, 32, 16)           0         ['activation[0][0]',          \n",
            "                                                                     'batch_normalization_2[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " activation_2 (Activation)   (None, 32, 32, 16)           0         ['add[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)           (None, 32, 32, 16)           2320      ['activation_2[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_3 (Bat  (None, 32, 32, 16)           64        ['conv2d_3[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_3 (Activation)   (None, 32, 32, 16)           0         ['batch_normalization_3[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)           (None, 32, 32, 16)           2320      ['activation_3[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_4 (Bat  (None, 32, 32, 16)           64        ['conv2d_4[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " add_1 (Add)                 (None, 32, 32, 16)           0         ['activation_2[0][0]',        \n",
            "                                                                     'batch_normalization_4[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " activation_4 (Activation)   (None, 32, 32, 16)           0         ['add_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)           (None, 32, 32, 16)           2320      ['activation_4[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_5 (Bat  (None, 32, 32, 16)           64        ['conv2d_5[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_5 (Activation)   (None, 32, 32, 16)           0         ['batch_normalization_5[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)           (None, 32, 32, 16)           2320      ['activation_5[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_6 (Bat  (None, 32, 32, 16)           64        ['conv2d_6[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " add_2 (Add)                 (None, 32, 32, 16)           0         ['activation_4[0][0]',        \n",
            "                                                                     'batch_normalization_6[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " activation_6 (Activation)   (None, 32, 32, 16)           0         ['add_2[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)           (None, 16, 16, 32)           4640      ['activation_6[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_7 (Bat  (None, 16, 16, 32)           128       ['conv2d_7[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_7 (Activation)   (None, 16, 16, 32)           0         ['batch_normalization_7[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)           (None, 16, 16, 32)           9248      ['activation_7[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)           (None, 16, 16, 32)           544       ['activation_6[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_8 (Bat  (None, 16, 16, 32)           128       ['conv2d_8[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " add_3 (Add)                 (None, 16, 16, 32)           0         ['conv2d_9[0][0]',            \n",
            "                                                                     'batch_normalization_8[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " activation_8 (Activation)   (None, 16, 16, 32)           0         ['add_3[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)          (None, 16, 16, 32)           9248      ['activation_8[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_9 (Bat  (None, 16, 16, 32)           128       ['conv2d_10[0][0]']           \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_9 (Activation)   (None, 16, 16, 32)           0         ['batch_normalization_9[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)          (None, 16, 16, 32)           9248      ['activation_9[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_10 (Ba  (None, 16, 16, 32)           128       ['conv2d_11[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_4 (Add)                 (None, 16, 16, 32)           0         ['activation_8[0][0]',        \n",
            "                                                                     'batch_normalization_10[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_10 (Activation)  (None, 16, 16, 32)           0         ['add_4[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)          (None, 16, 16, 32)           9248      ['activation_10[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_11 (Ba  (None, 16, 16, 32)           128       ['conv2d_12[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_11 (Activation)  (None, 16, 16, 32)           0         ['batch_normalization_11[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)          (None, 16, 16, 32)           9248      ['activation_11[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_12 (Ba  (None, 16, 16, 32)           128       ['conv2d_13[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_5 (Add)                 (None, 16, 16, 32)           0         ['activation_10[0][0]',       \n",
            "                                                                     'batch_normalization_12[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_12 (Activation)  (None, 16, 16, 32)           0         ['add_5[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)          (None, 8, 8, 64)             18496     ['activation_12[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_13 (Ba  (None, 8, 8, 64)             256       ['conv2d_14[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_13 (Activation)  (None, 8, 8, 64)             0         ['batch_normalization_13[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)          (None, 8, 8, 64)             36928     ['activation_13[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)          (None, 8, 8, 64)             2112      ['activation_12[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_14 (Ba  (None, 8, 8, 64)             256       ['conv2d_15[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_6 (Add)                 (None, 8, 8, 64)             0         ['conv2d_16[0][0]',           \n",
            "                                                                     'batch_normalization_14[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_14 (Activation)  (None, 8, 8, 64)             0         ['add_6[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)          (None, 8, 8, 64)             36928     ['activation_14[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_15 (Ba  (None, 8, 8, 64)             256       ['conv2d_17[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_15 (Activation)  (None, 8, 8, 64)             0         ['batch_normalization_15[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)          (None, 8, 8, 64)             36928     ['activation_15[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_16 (Ba  (None, 8, 8, 64)             256       ['conv2d_18[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_7 (Add)                 (None, 8, 8, 64)             0         ['activation_14[0][0]',       \n",
            "                                                                     'batch_normalization_16[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_16 (Activation)  (None, 8, 8, 64)             0         ['add_7[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)          (None, 8, 8, 64)             36928     ['activation_16[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_17 (Ba  (None, 8, 8, 64)             256       ['conv2d_19[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_17 (Activation)  (None, 8, 8, 64)             0         ['batch_normalization_17[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)          (None, 8, 8, 64)             36928     ['activation_17[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_18 (Ba  (None, 8, 8, 64)             256       ['conv2d_20[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_8 (Add)                 (None, 8, 8, 64)             0         ['activation_16[0][0]',       \n",
            "                                                                     'batch_normalization_18[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_18 (Activation)  (None, 8, 8, 64)             0         ['add_8[0][0]']               \n",
            "                                                                                                  \n",
            " average_pooling2d (Average  (None, 1, 1, 64)             0         ['activation_18[0][0]']       \n",
            " Pooling2D)                                                                                       \n",
            "                                                                                                  \n",
            " flatten (Flatten)           (None, 64)                   0         ['average_pooling2d[0][0]']   \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 10)                   650       ['flatten[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 274442 (1.05 MB)\n",
            "Trainable params: 273066 (1.04 MB)\n",
            "Non-trainable params: 1376 (5.38 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(lr=lr_schedule(0)),\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7pDgk15_sV6",
        "outputId": "859b19e0-9273-47a5-da75-789dbb1d694f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are, in total, 274442 parameters in this model!\n"
          ]
        }
      ],
      "source": [
        "print(\"There are, in total, {} parameters in this model!\".format(model.count_params()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSgdkpMo_sV6"
      },
      "source": [
        "### Prepare model saving directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "DTp8-MMY_sV6"
      },
      "outputs": [],
      "source": [
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'cifar10_%s_model.{epoch:03d}.h5' % model_type\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "filepath = os.path.join(save_dir, model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7xBG4Bo_sV6"
      },
      "source": [
        "### Prepare callbacks for model saving and for learning rate adjustment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhI7jvK9_sV6",
        "outputId": "8043d82a-14c7-4cb5-95f0-f84936c9a702"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        }
      ],
      "source": [
        "checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                             monitor='val_acc',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True,\n",
        "                             period=3\n",
        "                            )\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
        "                               cooldown=0,\n",
        "                               patience=5,\n",
        "                               min_lr=0.5e-6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "zRxHXnW5_sV7"
      },
      "outputs": [],
      "source": [
        "# For now, we will not save the models, so won't include the `checkpoint` in the `callbacks`\n",
        "callbacks = [lr_reducer, lr_scheduler]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAVx9_xD_sV7"
      },
      "source": [
        "### Training (sit back and enjoy a cuppa, because this is gonna take some time!)\n",
        "First start with a very small number of epochs to check the training speed on your particular hardware. Thereafter, adjust accordingly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "W30MzznM_sV7"
      },
      "outputs": [],
      "source": [
        "from time import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "enHO8rzW_sV7"
      },
      "outputs": [],
      "source": [
        "batch_size = 32  # orig paper trained all networks with batch_size=128\n",
        "epochs = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQwFPB-7_sV7",
        "outputId": "40e1264d-6ea0-4581-ba46-ee415b2ff043"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate:  0.001\n",
            "Epoch 1/20\n",
            "1563/1563 [==============================] - 52s 18ms/step - loss: 1.4661 - accuracy: 0.5260 - val_loss: 1.3946 - val_accuracy: 0.5789 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 2/20\n",
            "1563/1563 [==============================] - 28s 18ms/step - loss: 1.0611 - accuracy: 0.6815 - val_loss: 1.4826 - val_accuracy: 0.5662 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 3/20\n",
            "1563/1563 [==============================] - 28s 18ms/step - loss: 0.9009 - accuracy: 0.7414 - val_loss: 1.1183 - val_accuracy: 0.6669 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 4/20\n",
            "1563/1563 [==============================] - 27s 17ms/step - loss: 0.7960 - accuracy: 0.7826 - val_loss: 1.0227 - val_accuracy: 0.7155 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 5/20\n",
            "1563/1563 [==============================] - 27s 17ms/step - loss: 0.7264 - accuracy: 0.8081 - val_loss: 0.8914 - val_accuracy: 0.7580 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 6/20\n",
            "1563/1563 [==============================] - 27s 17ms/step - loss: 0.6752 - accuracy: 0.8278 - val_loss: 0.9078 - val_accuracy: 0.7549 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 7/20\n",
            "1563/1563 [==============================] - 28s 18ms/step - loss: 0.6330 - accuracy: 0.8425 - val_loss: 0.8779 - val_accuracy: 0.7723 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 8/20\n",
            "1563/1563 [==============================] - 27s 17ms/step - loss: 0.6012 - accuracy: 0.8567 - val_loss: 0.8234 - val_accuracy: 0.7925 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 9/20\n",
            "1563/1563 [==============================] - 28s 18ms/step - loss: 0.5722 - accuracy: 0.8684 - val_loss: 0.9028 - val_accuracy: 0.7762 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 10/20\n",
            "1563/1563 [==============================] - 27s 17ms/step - loss: 0.5475 - accuracy: 0.8794 - val_loss: 0.9372 - val_accuracy: 0.7651 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 11/20\n",
            "1563/1563 [==============================] - 28s 18ms/step - loss: 0.5275 - accuracy: 0.8880 - val_loss: 1.0832 - val_accuracy: 0.7407 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 12/20\n",
            "1563/1563 [==============================] - 27s 17ms/step - loss: 0.5125 - accuracy: 0.8947 - val_loss: 0.9154 - val_accuracy: 0.7797 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 13/20\n",
            "1563/1563 [==============================] - 27s 17ms/step - loss: 0.4965 - accuracy: 0.9031 - val_loss: 0.9771 - val_accuracy: 0.7677 - lr: 3.1623e-04\n",
            "Learning rate:  0.001\n",
            "Epoch 14/20\n",
            "1563/1563 [==============================] - 27s 17ms/step - loss: 0.4847 - accuracy: 0.9086 - val_loss: 1.0116 - val_accuracy: 0.7718 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 15/20\n",
            "1563/1563 [==============================] - 27s 17ms/step - loss: 0.4768 - accuracy: 0.9136 - val_loss: 1.3140 - val_accuracy: 0.7034 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 16/20\n",
            "1563/1563 [==============================] - 28s 18ms/step - loss: 0.4677 - accuracy: 0.9177 - val_loss: 0.9593 - val_accuracy: 0.7962 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 17/20\n",
            "1563/1563 [==============================] - 27s 17ms/step - loss: 0.4621 - accuracy: 0.9213 - val_loss: 1.0115 - val_accuracy: 0.7908 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 18/20\n",
            "1563/1563 [==============================] - 27s 17ms/step - loss: 0.4530 - accuracy: 0.9257 - val_loss: 1.0213 - val_accuracy: 0.7899 - lr: 3.1623e-04\n",
            "Learning rate:  0.001\n",
            "Epoch 19/20\n",
            "1563/1563 [==============================] - 28s 18ms/step - loss: 0.4511 - accuracy: 0.9276 - val_loss: 1.1867 - val_accuracy: 0.7689 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 20/20\n",
            "1563/1563 [==============================] - 27s 17ms/step - loss: 0.4449 - accuracy: 0.9306 - val_loss: 1.0144 - val_accuracy: 0.7930 - lr: 0.0010\n"
          ]
        }
      ],
      "source": [
        "t1 = time()\n",
        "model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              verbose=1,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True,\n",
        "              callbacks=callbacks)\n",
        "t2 = time()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"model_resnet01.h6\")\n",
        "import zipfile, os\n",
        "folder_path = 'model_resnet01.h6'\n",
        "zip_file_name = 'model_resnet01.h6.zip'\n",
        "\n",
        "def zip_folder(folder_path, zip_file_name):\n",
        "    zip_file = zipfile.ZipFile(zip_file_name, 'w')\n",
        "\n",
        "    for root, dirs, files in os.walk(folder_path):\n",
        "        for file in files:\n",
        "            zip_file.write(os.path.join(root, file))\n",
        "\n",
        "    zip_file.close()\n",
        "zip_folder(folder_path, zip_file_name)"
      ],
      "metadata": {
        "id": "fqp6ufK4g4Ar"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "rARLMs7y_sV7",
        "outputId": "36afa8ae-42ca-4c1e-f1ca-ec753c01386c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training of 20 epochs took 10.49 minutes total.\n"
          ]
        }
      ],
      "source": [
        "time_delta=round((t2-t1)/60,2)\n",
        "\n",
        "print (\"Training of {} epochs took {} minutes total.\".format(epochs, time_delta))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUjvryPq_sV8"
      },
      "source": [
        "### Score trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "9IAkDxUA_sV8",
        "outputId": "25edbdf0-14b0-4266-8271-4bcd3e7c59d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 2s 7ms/step - loss: 1.0144 - accuracy: 0.7930\n",
            "Test loss: 1.0144305229187012\n",
            "Test accuracy: 0.7929999828338623\n"
          ]
        }
      ],
      "source": [
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRhemevq_sV8"
      },
      "source": [
        "### A smaller learning rate and larger batch size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N1ihHs8d_sV9"
      },
      "outputs": [],
      "source": [
        "# Note, we turn off the callbacks as we want to use the new learning rate\n",
        "t1 = time()\n",
        "model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              verbose=1,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True)\n",
        "t2 = time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cU5hY4e0_sV9"
      },
      "outputs": [],
      "source": [
        "time_delta=round((t2-t1)/60,2)\n",
        "\n",
        "print (\"Training of {} epochs took {} minutes total.\".format(epochs, time_delta))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sử dụng lại model dùng resnet v1 và Fit with data augmentation"
      ],
      "metadata": {
        "id": "tqUqmY78i4RV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "model = tf.keras.models.load_model('model_resnet01.h6')\n"
      ],
      "metadata": {
        "id": "KhXq9TdVi3Wb"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "data_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
        "\n",
        "train_generator = data_generator.flow(x_train, y_train, batch_size)\n",
        "steps_per_epoch = x_train.shape[0] // batch_size"
      ],
      "metadata": {
        "id": "ibeHopqvj5qL"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = time()\n",
        "r = model.fit(train_generator, validation_data=(x_test, y_test),\n",
        "\t\t\tsteps_per_epoch=steps_per_epoch, epochs=50)\n",
        "\n",
        "t2 = time()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7B-WvoRj1rg",
        "outputId": "3da1193b-b97a-412c-c1cd-bdf02f66e4c7"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.4794 - accuracy: 0.9052 - val_loss: 0.6346 - val_accuracy: 0.8599\n",
            "Epoch 2/50\n",
            "781/781 [==============================] - 39s 50ms/step - loss: 0.4685 - accuracy: 0.9048 - val_loss: 0.6891 - val_accuracy: 0.8447\n",
            "Epoch 3/50\n",
            "781/781 [==============================] - 38s 48ms/step - loss: 0.4672 - accuracy: 0.9051 - val_loss: 0.6672 - val_accuracy: 0.8526\n",
            "Epoch 4/50\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.4665 - accuracy: 0.9045 - val_loss: 0.6267 - val_accuracy: 0.8572\n",
            "Epoch 5/50\n",
            "781/781 [==============================] - 39s 50ms/step - loss: 0.4633 - accuracy: 0.9041 - val_loss: 0.7012 - val_accuracy: 0.8410\n",
            "Epoch 6/50\n",
            "781/781 [==============================] - 39s 50ms/step - loss: 0.4651 - accuracy: 0.9013 - val_loss: 0.6181 - val_accuracy: 0.8558\n",
            "Epoch 7/50\n",
            "781/781 [==============================] - 39s 50ms/step - loss: 0.4551 - accuracy: 0.9062 - val_loss: 0.8148 - val_accuracy: 0.8117\n",
            "Epoch 8/50\n",
            "781/781 [==============================] - 40s 51ms/step - loss: 0.4522 - accuracy: 0.9072 - val_loss: 0.7895 - val_accuracy: 0.8201\n",
            "Epoch 9/50\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.4511 - accuracy: 0.9054 - val_loss: 0.6040 - val_accuracy: 0.8617\n",
            "Epoch 10/50\n",
            "781/781 [==============================] - 38s 48ms/step - loss: 0.4431 - accuracy: 0.9094 - val_loss: 0.7738 - val_accuracy: 0.8165\n",
            "Epoch 11/50\n",
            "781/781 [==============================] - 38s 48ms/step - loss: 0.4476 - accuracy: 0.9073 - val_loss: 0.7710 - val_accuracy: 0.8196\n",
            "Epoch 12/50\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.4446 - accuracy: 0.9078 - val_loss: 0.6017 - val_accuracy: 0.8687\n",
            "Epoch 13/50\n",
            "781/781 [==============================] - 38s 48ms/step - loss: 0.4472 - accuracy: 0.9085 - val_loss: 0.5859 - val_accuracy: 0.8629\n",
            "Epoch 14/50\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.4402 - accuracy: 0.9102 - val_loss: 0.6321 - val_accuracy: 0.8537\n",
            "Epoch 15/50\n",
            "781/781 [==============================] - 39s 50ms/step - loss: 0.4337 - accuracy: 0.9124 - val_loss: 0.6616 - val_accuracy: 0.8477\n",
            "Epoch 16/50\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.4358 - accuracy: 0.9108 - val_loss: 0.6269 - val_accuracy: 0.8566\n",
            "Epoch 17/50\n",
            "781/781 [==============================] - 39s 50ms/step - loss: 0.4343 - accuracy: 0.9129 - val_loss: 0.6758 - val_accuracy: 0.8466\n",
            "Epoch 18/50\n",
            "781/781 [==============================] - 39s 50ms/step - loss: 0.4327 - accuracy: 0.9115 - val_loss: 0.8194 - val_accuracy: 0.8097\n",
            "Epoch 19/50\n",
            "781/781 [==============================] - 40s 52ms/step - loss: 0.4321 - accuracy: 0.9120 - val_loss: 1.0006 - val_accuracy: 0.7741\n",
            "Epoch 20/50\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.4266 - accuracy: 0.9142 - val_loss: 0.5833 - val_accuracy: 0.8668\n",
            "Epoch 21/50\n",
            "781/781 [==============================] - 39s 50ms/step - loss: 0.4323 - accuracy: 0.9126 - val_loss: 0.6481 - val_accuracy: 0.8540\n",
            "Epoch 22/50\n",
            "781/781 [==============================] - 39s 50ms/step - loss: 0.4253 - accuracy: 0.9149 - val_loss: 0.6621 - val_accuracy: 0.8439\n",
            "Epoch 23/50\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.4238 - accuracy: 0.9150 - val_loss: 0.6084 - val_accuracy: 0.8645\n",
            "Epoch 24/50\n",
            "781/781 [==============================] - 38s 48ms/step - loss: 0.4273 - accuracy: 0.9138 - val_loss: 0.8942 - val_accuracy: 0.8035\n",
            "Epoch 25/50\n",
            "781/781 [==============================] - 39s 50ms/step - loss: 0.4218 - accuracy: 0.9166 - val_loss: 0.5806 - val_accuracy: 0.8707\n",
            "Epoch 26/50\n",
            "781/781 [==============================] - 40s 51ms/step - loss: 0.4270 - accuracy: 0.9133 - val_loss: 0.7586 - val_accuracy: 0.8324\n",
            "Epoch 27/50\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.4283 - accuracy: 0.9135 - val_loss: 0.6747 - val_accuracy: 0.8440\n",
            "Epoch 28/50\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.4235 - accuracy: 0.9161 - val_loss: 0.5998 - val_accuracy: 0.8674\n",
            "Epoch 29/50\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.4239 - accuracy: 0.9151 - val_loss: 0.5927 - val_accuracy: 0.8738\n",
            "Epoch 30/50\n",
            "781/781 [==============================] - 39s 49ms/step - loss: 0.4195 - accuracy: 0.9162 - val_loss: 0.6417 - val_accuracy: 0.8535\n",
            "Epoch 31/50\n",
            "781/781 [==============================] - 38s 48ms/step - loss: 0.4225 - accuracy: 0.9171 - val_loss: 0.6038 - val_accuracy: 0.8684\n",
            "Epoch 32/50\n",
            "781/781 [==============================] - 39s 50ms/step - loss: 0.4200 - accuracy: 0.9167 - val_loss: 0.7232 - val_accuracy: 0.8359\n",
            "Epoch 33/50\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.4153 - accuracy: 0.9189 - val_loss: 0.5897 - val_accuracy: 0.8701\n",
            "Epoch 34/50\n",
            "781/781 [==============================] - 38s 48ms/step - loss: 0.4175 - accuracy: 0.9170 - val_loss: 0.7618 - val_accuracy: 0.8264\n",
            "Epoch 35/50\n",
            "781/781 [==============================] - 40s 51ms/step - loss: 0.4189 - accuracy: 0.9172 - val_loss: 0.6787 - val_accuracy: 0.8440\n",
            "Epoch 36/50\n",
            "781/781 [==============================] - 39s 50ms/step - loss: 0.4165 - accuracy: 0.9174 - val_loss: 0.8775 - val_accuracy: 0.8088\n",
            "Epoch 37/50\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.4161 - accuracy: 0.9185 - val_loss: 0.7063 - val_accuracy: 0.8396\n",
            "Epoch 38/50\n",
            "781/781 [==============================] - 40s 51ms/step - loss: 0.4155 - accuracy: 0.9190 - val_loss: 0.6317 - val_accuracy: 0.8607\n",
            "Epoch 39/50\n",
            "781/781 [==============================] - 40s 51ms/step - loss: 0.4174 - accuracy: 0.9176 - val_loss: 0.5987 - val_accuracy: 0.8722\n",
            "Epoch 40/50\n",
            "781/781 [==============================] - 39s 50ms/step - loss: 0.4176 - accuracy: 0.9183 - val_loss: 0.6295 - val_accuracy: 0.8631\n",
            "Epoch 41/50\n",
            "781/781 [==============================] - 39s 50ms/step - loss: 0.4131 - accuracy: 0.9195 - val_loss: 0.6100 - val_accuracy: 0.8642\n",
            "Epoch 42/50\n",
            "781/781 [==============================] - 40s 51ms/step - loss: 0.4150 - accuracy: 0.9170 - val_loss: 0.7500 - val_accuracy: 0.8287\n",
            "Epoch 43/50\n",
            "781/781 [==============================] - 40s 51ms/step - loss: 0.4158 - accuracy: 0.9196 - val_loss: 0.8259 - val_accuracy: 0.8119\n",
            "Epoch 44/50\n",
            "781/781 [==============================] - 39s 49ms/step - loss: 0.4098 - accuracy: 0.9207 - val_loss: 0.6053 - val_accuracy: 0.8689\n",
            "Epoch 45/50\n",
            "781/781 [==============================] - 39s 50ms/step - loss: 0.4127 - accuracy: 0.9192 - val_loss: 0.6634 - val_accuracy: 0.8555\n",
            "Epoch 46/50\n",
            "781/781 [==============================] - 40s 52ms/step - loss: 0.4077 - accuracy: 0.9207 - val_loss: 0.6232 - val_accuracy: 0.8624\n",
            "Epoch 47/50\n",
            "781/781 [==============================] - 42s 53ms/step - loss: 0.4101 - accuracy: 0.9197 - val_loss: 0.6418 - val_accuracy: 0.8647\n",
            "Epoch 48/50\n",
            "781/781 [==============================] - 39s 50ms/step - loss: 0.4076 - accuracy: 0.9213 - val_loss: 0.6729 - val_accuracy: 0.8479\n",
            "Epoch 49/50\n",
            "781/781 [==============================] - 41s 52ms/step - loss: 0.4066 - accuracy: 0.9214 - val_loss: 0.5855 - val_accuracy: 0.8707\n",
            "Epoch 50/50\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.4028 - accuracy: 0.9243 - val_loss: 0.6093 - val_accuracy: 0.8620\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"model_resnet03.h6\")\n",
        "import zipfile, os\n",
        "folder_path = 'model_resnet03.h6'\n",
        "zip_file_name = 'model_resnet03.h6.zip'\n",
        "\n",
        "def zip_folder(folder_path, zip_file_name):\n",
        "    zip_file = zipfile.ZipFile(zip_file_name, 'w')\n",
        "\n",
        "    for root, dirs, files in os.walk(folder_path):\n",
        "        for file in files:\n",
        "            zip_file.write(os.path.join(root, file))\n",
        "\n",
        "    zip_file.close()\n",
        "zip_folder(folder_path, zip_file_name)"
      ],
      "metadata": {
        "id": "KPylLMWTo8JX"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "time_delta=round((t2-t1)/60,2)\n",
        "\n",
        "print (\"Training of {} epochs took {} minutes total.\".format(epochs, time_delta))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOOLnehhxPjU",
        "outputId": "e72ddf0f-a0be-4a52-8e82-64e61f16f397"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training of 20 epochs took 33.55 minutes total.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "metadata": {
        "id": "OknoC2V4xWMj",
        "outputId": "5fb467ba-70a4-40b6-9592-380d64407c65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 2s 7ms/step - loss: 0.6093 - accuracy: 0.8620\n",
            "Test loss: 0.60933518409729\n",
            "Test accuracy: 0.8619999885559082\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZ0K4j_4_sV9"
      },
      "source": [
        "### With ResNet v2 model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZZkC4AS_sV9",
        "outputId": "cf2cad15-5a26-4802-cd87-19912d91773d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model type: ResNet47v2\n",
            "There are, in total, 1398826 parameters in this model!\n"
          ]
        }
      ],
      "source": [
        "version = 2\n",
        "n = 5\n",
        "\n",
        "depth = model_depth(version=version,n=n)\n",
        "model = choose_model(version)\n",
        "\n",
        "print(\"Model type:\",model_type(version,n))\n",
        "print(\"There are, in total, {} parameters in this model!\".format(model.count_params()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2zn8sVg_sV-"
      },
      "outputs": [],
      "source": [
        "# Hard coding the learning rate = 3e-4\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(lr=3e-4),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VoucryJg_sV-"
      },
      "outputs": [],
      "source": [
        "batch_size = 128  # orig paper trained all networks with batch_size=128\n",
        "epochs = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05Gko2Hv_sV-",
        "outputId": "926ef7f0-94bf-401b-a1bb-715696b2fdc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "50000/50000 [==============================] - 110s 2ms/step - loss: 2.4201 - acc: 0.4460 - val_loss: 2.2206 - val_acc: 0.4953\n",
            "Epoch 2/20\n",
            "50000/50000 [==============================] - 80s 2ms/step - loss: 1.9250 - acc: 0.5916 - val_loss: 1.8745 - val_acc: 0.5946\n",
            "Epoch 3/20\n",
            "50000/50000 [==============================] - 80s 2ms/step - loss: 1.6684 - acc: 0.6650 - val_loss: 1.7502 - val_acc: 0.6214\n",
            "Epoch 4/20\n",
            "50000/50000 [==============================] - 81s 2ms/step - loss: 1.4783 - acc: 0.7201 - val_loss: 1.7839 - val_acc: 0.5964\n",
            "Epoch 5/20\n",
            "50000/50000 [==============================] - 81s 2ms/step - loss: 1.3153 - acc: 0.7691 - val_loss: 1.9695 - val_acc: 0.5663\n",
            "Epoch 6/20\n",
            "50000/50000 [==============================] - 81s 2ms/step - loss: 1.1650 - acc: 0.8159 - val_loss: 2.0570 - val_acc: 0.5618\n",
            "Epoch 7/20\n",
            "50000/50000 [==============================] - 81s 2ms/step - loss: 1.0283 - acc: 0.8606 - val_loss: 1.7825 - val_acc: 0.6336\n",
            "Epoch 8/20\n",
            "50000/50000 [==============================] - 81s 2ms/step - loss: 0.9047 - acc: 0.9012 - val_loss: 2.1000 - val_acc: 0.6138\n",
            "Epoch 9/20\n",
            "50000/50000 [==============================] - 81s 2ms/step - loss: 0.8266 - acc: 0.9233 - val_loss: 2.4783 - val_acc: 0.5880\n",
            "Epoch 10/20\n",
            "50000/50000 [==============================] - 81s 2ms/step - loss: 0.7639 - acc: 0.9430 - val_loss: 2.8940 - val_acc: 0.5157\n",
            "Epoch 11/20\n",
            "50000/50000 [==============================] - 81s 2ms/step - loss: 0.7229 - acc: 0.9545 - val_loss: 2.5297 - val_acc: 0.5880\n",
            "Epoch 12/20\n",
            "50000/50000 [==============================] - 81s 2ms/step - loss: 0.7020 - acc: 0.9579 - val_loss: 2.2610 - val_acc: 0.6122\n",
            "Epoch 13/20\n",
            "50000/50000 [==============================] - 82s 2ms/step - loss: 0.6785 - acc: 0.9634 - val_loss: 2.0715 - val_acc: 0.6554\n",
            "Epoch 14/20\n",
            "50000/50000 [==============================] - 82s 2ms/step - loss: 0.6669 - acc: 0.9641 - val_loss: 2.2667 - val_acc: 0.6290\n",
            "Epoch 15/20\n",
            "50000/50000 [==============================] - 82s 2ms/step - loss: 0.6467 - acc: 0.9693 - val_loss: 2.6547 - val_acc: 0.6102\n",
            "Epoch 16/20\n",
            "50000/50000 [==============================] - 82s 2ms/step - loss: 0.6351 - acc: 0.9710 - val_loss: 2.8041 - val_acc: 0.5869\n",
            "Epoch 17/20\n",
            "50000/50000 [==============================] - 81s 2ms/step - loss: 0.6197 - acc: 0.9736 - val_loss: 2.4689 - val_acc: 0.6145\n",
            "Epoch 18/20\n",
            "50000/50000 [==============================] - 81s 2ms/step - loss: 0.6084 - acc: 0.9751 - val_loss: 4.2802 - val_acc: 0.4618\n",
            "Epoch 19/20\n",
            "50000/50000 [==============================] - 81s 2ms/step - loss: 0.6149 - acc: 0.9713 - val_loss: 2.5493 - val_acc: 0.6121\n",
            "Epoch 20/20\n",
            "50000/50000 [==============================] - 81s 2ms/step - loss: 0.5959 - acc: 0.9760 - val_loss: 2.2993 - val_acc: 0.6470\n"
          ]
        }
      ],
      "source": [
        "# Note, we turn off the callbacks as we want to use the new learning rate\n",
        "t1 = time()\n",
        "model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              verbose=1,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True)\n",
        "t2 = time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4X5v8MPn_sV-",
        "outputId": "aa3f137f-c6e1-4c5d-d43b-8328a20f1c3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training of 20 epochs took 27.57 minutes total.\n"
          ]
        }
      ],
      "source": [
        "time_delta=round((t2-t1)/60,2)\n",
        "\n",
        "print (\"Training of {} epochs took {} minutes total.\".format(epochs, time_delta))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AV0DSjQH_sV_",
        "outputId": "d64a6b37-9be1-48eb-a79d-e10a48f7de38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 8s 773us/step\n",
            "Test loss: 2.2992931884765624\n",
            "Test accuracy: 0.647\n"
          ]
        }
      ],
      "source": [
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddz3P5sl_sWA"
      },
      "source": [
        "### More variation and longer training..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tz7blZ1o_sWA",
        "outputId": "87413e40-a57a-4237-d100-866973b11079"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model type: ResNet26v1\n",
            "There are, in total, 372330 parameters in this model!\n"
          ]
        }
      ],
      "source": [
        "version = 1\n",
        "n = 4\n",
        "\n",
        "depth = model_depth(version=version,n=n)\n",
        "model = choose_model(version)\n",
        "\n",
        "print(\"Model type:\",model_type(version,n))\n",
        "print(\"There are, in total, {} parameters in this model!\".format(model.count_params()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4LhT9N6_sWB"
      },
      "outputs": [],
      "source": [
        "# Hard coding the learning rate = 1e-3\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(lr=1e-3),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jIuIZ10M_sWB"
      },
      "outputs": [],
      "source": [
        "batch_size = 128  # orig paper trained all networks with batch_size=128\n",
        "epochs = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QRa_5Hkv_sWC"
      },
      "outputs": [],
      "source": [
        "callbacks = [lr_reducer]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vzpQ-aQj_sWC",
        "outputId": "811e4d1c-12bd-4593-d095-34bce6cfdc33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "50000/50000 [==============================] - 32s 631us/step - loss: 1.0204 - acc: 0.7070 - val_loss: 1.3248 - val_acc: 0.6230\n",
            "Epoch 2/50\n",
            "50000/50000 [==============================] - 31s 621us/step - loss: 0.8886 - acc: 0.7562 - val_loss: 1.8254 - val_acc: 0.5249\n",
            "Epoch 3/50\n",
            "50000/50000 [==============================] - 31s 622us/step - loss: 0.7859 - acc: 0.7894 - val_loss: 0.9916 - val_acc: 0.7328\n",
            "Epoch 4/50\n",
            "50000/50000 [==============================] - 31s 624us/step - loss: 0.7010 - acc: 0.8206 - val_loss: 1.5349 - val_acc: 0.6127\n",
            "Epoch 5/50\n",
            "50000/50000 [==============================] - 31s 630us/step - loss: 0.6452 - acc: 0.8400 - val_loss: 0.9615 - val_acc: 0.7466\n",
            "Epoch 6/50\n",
            "50000/50000 [==============================] - 31s 630us/step - loss: 0.5894 - acc: 0.8588 - val_loss: 0.9448 - val_acc: 0.7522\n",
            "Epoch 7/50\n",
            "50000/50000 [==============================] - 32s 636us/step - loss: 0.5459 - acc: 0.8761 - val_loss: 1.1748 - val_acc: 0.7155\n",
            "Epoch 8/50\n",
            "50000/50000 [==============================] - 31s 630us/step - loss: 0.5060 - acc: 0.8900 - val_loss: 1.3657 - val_acc: 0.6986\n",
            "Epoch 9/50\n",
            "50000/50000 [==============================] - 31s 628us/step - loss: 0.4642 - acc: 0.9045 - val_loss: 1.4428 - val_acc: 0.6682\n",
            "Epoch 10/50\n",
            "50000/50000 [==============================] - 32s 631us/step - loss: 0.4307 - acc: 0.9177 - val_loss: 1.3192 - val_acc: 0.7142\n",
            "Epoch 11/50\n",
            "50000/50000 [==============================] - 31s 629us/step - loss: 0.4162 - acc: 0.9235 - val_loss: 1.6899 - val_acc: 0.6612\n",
            "Epoch 12/50\n",
            "50000/50000 [==============================] - 31s 628us/step - loss: 0.2813 - acc: 0.9769 - val_loss: 0.9175 - val_acc: 0.8019\n",
            "Epoch 13/50\n",
            "50000/50000 [==============================] - 31s 628us/step - loss: 0.2341 - acc: 0.9920 - val_loss: 0.9335 - val_acc: 0.8052\n",
            "Epoch 14/50\n",
            "50000/50000 [==============================] - 31s 629us/step - loss: 0.2139 - acc: 0.9964 - val_loss: 1.0254 - val_acc: 0.7984\n",
            "Epoch 15/50\n",
            "50000/50000 [==============================] - 32s 631us/step - loss: 0.2044 - acc: 0.9973 - val_loss: 1.0121 - val_acc: 0.8029\n",
            "Epoch 16/50\n",
            "50000/50000 [==============================] - 32s 631us/step - loss: 0.1974 - acc: 0.9974 - val_loss: 1.1791 - val_acc: 0.7870\n",
            "Epoch 17/50\n",
            "50000/50000 [==============================] - 32s 630us/step - loss: 0.1964 - acc: 0.9953 - val_loss: 1.1734 - val_acc: 0.7929\n",
            "Epoch 18/50\n",
            "50000/50000 [==============================] - 32s 631us/step - loss: 0.1835 - acc: 0.9988 - val_loss: 1.0928 - val_acc: 0.8059\n",
            "Epoch 19/50\n",
            "50000/50000 [==============================] - 32s 631us/step - loss: 0.1766 - acc: 0.9997 - val_loss: 1.0741 - val_acc: 0.8076\n",
            "Epoch 20/50\n",
            "50000/50000 [==============================] - 32s 634us/step - loss: 0.1730 - acc: 0.9999 - val_loss: 1.0837 - val_acc: 0.8075\n",
            "Epoch 21/50\n",
            "50000/50000 [==============================] - 32s 632us/step - loss: 0.1701 - acc: 0.9999 - val_loss: 1.1360 - val_acc: 0.8025\n",
            "Epoch 22/50\n",
            "50000/50000 [==============================] - 32s 632us/step - loss: 0.1662 - acc: 1.0000 - val_loss: 1.1012 - val_acc: 0.8078\n",
            "Epoch 23/50\n",
            "50000/50000 [==============================] - 32s 632us/step - loss: 0.1635 - acc: 1.0000 - val_loss: 1.1208 - val_acc: 0.8077\n",
            "Epoch 24/50\n",
            "50000/50000 [==============================] - 32s 631us/step - loss: 0.1621 - acc: 1.0000 - val_loss: 1.1175 - val_acc: 0.8084\n",
            "Epoch 25/50\n",
            "50000/50000 [==============================] - 33s 654us/step - loss: 0.1604 - acc: 1.0000 - val_loss: 1.1125 - val_acc: 0.8088\n",
            "Epoch 26/50\n",
            "50000/50000 [==============================] - 32s 637us/step - loss: 0.1589 - acc: 1.0000 - val_loss: 1.1141 - val_acc: 0.8097\n",
            "Epoch 27/50\n",
            "50000/50000 [==============================] - 32s 631us/step - loss: 0.1568 - acc: 1.0000 - val_loss: 1.1280 - val_acc: 0.8074\n",
            "Epoch 28/50\n",
            "50000/50000 [==============================] - 32s 633us/step - loss: 0.1553 - acc: 1.0000 - val_loss: 1.1258 - val_acc: 0.8089\n",
            "Epoch 29/50\n",
            "50000/50000 [==============================] - 32s 633us/step - loss: 0.1545 - acc: 1.0000 - val_loss: 1.1250 - val_acc: 0.8076\n",
            "Epoch 30/50\n",
            "50000/50000 [==============================] - 32s 633us/step - loss: 0.1536 - acc: 1.0000 - val_loss: 1.1288 - val_acc: 0.8074\n",
            "Epoch 31/50\n",
            "50000/50000 [==============================] - 32s 634us/step - loss: 0.1526 - acc: 1.0000 - val_loss: 1.1328 - val_acc: 0.8079\n",
            "Epoch 32/50\n",
            "50000/50000 [==============================] - 32s 634us/step - loss: 0.1516 - acc: 1.0000 - val_loss: 1.1321 - val_acc: 0.8083\n",
            "Epoch 33/50\n",
            "50000/50000 [==============================] - 32s 634us/step - loss: 0.1509 - acc: 1.0000 - val_loss: 1.1336 - val_acc: 0.8078\n",
            "Epoch 34/50\n",
            "50000/50000 [==============================] - 32s 634us/step - loss: 0.1505 - acc: 1.0000 - val_loss: 1.1374 - val_acc: 0.8083\n",
            "Epoch 35/50\n",
            "50000/50000 [==============================] - 33s 654us/step - loss: 0.1501 - acc: 1.0000 - val_loss: 1.1369 - val_acc: 0.8076\n",
            "Epoch 36/50\n",
            "50000/50000 [==============================] - 32s 634us/step - loss: 0.1498 - acc: 1.0000 - val_loss: 1.1373 - val_acc: 0.8073\n",
            "Epoch 37/50\n",
            "50000/50000 [==============================] - 32s 633us/step - loss: 0.1494 - acc: 1.0000 - val_loss: 1.1381 - val_acc: 0.8072\n",
            "Epoch 38/50\n",
            "50000/50000 [==============================] - 32s 634us/step - loss: 0.1491 - acc: 1.0000 - val_loss: 1.1379 - val_acc: 0.8074\n",
            "Epoch 39/50\n",
            "50000/50000 [==============================] - 32s 643us/step - loss: 0.1490 - acc: 1.0000 - val_loss: 1.1406 - val_acc: 0.8073\n",
            "Epoch 40/50\n",
            "50000/50000 [==============================] - 32s 638us/step - loss: 0.1489 - acc: 1.0000 - val_loss: 1.1385 - val_acc: 0.8072\n",
            "Epoch 41/50\n",
            "50000/50000 [==============================] - 32s 639us/step - loss: 0.1487 - acc: 1.0000 - val_loss: 1.1407 - val_acc: 0.8076\n",
            "Epoch 42/50\n",
            "50000/50000 [==============================] - 33s 666us/step - loss: 0.1485 - acc: 1.0000 - val_loss: 1.1399 - val_acc: 0.8070\n",
            "Epoch 43/50\n",
            "50000/50000 [==============================] - 32s 641us/step - loss: 0.1484 - acc: 1.0000 - val_loss: 1.1395 - val_acc: 0.8079\n",
            "Epoch 44/50\n",
            "50000/50000 [==============================] - 32s 638us/step - loss: 0.1484 - acc: 1.0000 - val_loss: 1.1411 - val_acc: 0.8079\n",
            "Epoch 45/50\n",
            "50000/50000 [==============================] - 32s 637us/step - loss: 0.1483 - acc: 1.0000 - val_loss: 1.1398 - val_acc: 0.8074\n",
            "Epoch 46/50\n",
            "50000/50000 [==============================] - 32s 637us/step - loss: 0.1483 - acc: 1.0000 - val_loss: 1.1410 - val_acc: 0.8073\n",
            "Epoch 47/50\n",
            "50000/50000 [==============================] - 32s 641us/step - loss: 0.1481 - acc: 1.0000 - val_loss: 1.1405 - val_acc: 0.8075\n",
            "Epoch 48/50\n",
            "50000/50000 [==============================] - 32s 640us/step - loss: 0.1481 - acc: 1.0000 - val_loss: 1.1414 - val_acc: 0.8072\n",
            "Epoch 49/50\n",
            "50000/50000 [==============================] - 32s 637us/step - loss: 0.1480 - acc: 1.0000 - val_loss: 1.1417 - val_acc: 0.8075\n",
            "Epoch 50/50\n",
            "50000/50000 [==============================] - 32s 635us/step - loss: 0.1479 - acc: 1.0000 - val_loss: 1.1411 - val_acc: 0.8073\n"
          ]
        }
      ],
      "source": [
        "# Note, we turn off the callbacks as we want to use the new learning rate\n",
        "t1 = time()\n",
        "model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              verbose=1,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True,\n",
        "              callbacks=callbacks)\n",
        "t2 = time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O4h5IiEa_sWC",
        "outputId": "1760d5cc-f909-4b73-923a-ba549c9bed91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training of 50 epochs took 26.55 minutes total.\n"
          ]
        }
      ],
      "source": [
        "time_delta=round((t2-t1)/60,2)\n",
        "\n",
        "print (\"Training of {} epochs took {} minutes total.\".format(epochs, time_delta))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32wvemy3_sWD",
        "outputId": "5ef7d6da-261b-45a3-9ff2-8894f41cfb59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 4s 432us/step\n",
            "Test loss: 1.1410504387378693\n",
            "Test accuracy: 0.8073\n"
          ]
        }
      ],
      "source": [
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}