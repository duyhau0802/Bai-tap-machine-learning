{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GODH76PUC5Sw"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n"
      ],
      "metadata": {
        "id": "InQg_yZFC_OU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(train_data, batch_size=4, shuffle=True, num_workers=2)\n",
        "\n",
        "test_data = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(test_data, batch_size=4, shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('Airplane', 'Car', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3oAwne9DCyp",
        "outputId": "3b98b57e-0310-4783-b19b-1c3d92612232"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:13<00:00, 13052858.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Now using the AlexNet\n",
        "AlexNet_Model = torch.hub.load('pytorch/vision:v0.6.0', 'alexnet', pretrained=True)\n",
        "AlexNet_Model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7IYK2XCDIBL",
        "outputId": "a15c1cbe-6ae1-4784-b43e-63074125c720"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/pytorch/vision/zipball/v0.6.0\" to /root/.cache/torch/hub/v0.6.0.zip\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n",
            "100%|██████████| 233M/233M [00:01<00:00, 216MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AlexNet(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): ReLU(inplace=True)\n",
              "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.5, inplace=False)\n",
              "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Dropout(p=0.5, inplace=False)\n",
              "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "AlexNet_Model.classifier[1] = nn.Linear(9216,4096)\n",
        "AlexNet_Model.classifier[4] = nn.Linear(4096,1024)\n",
        "AlexNet_Model.classifier[6] = nn.Linear(1024,10)\n"
      ],
      "metadata": {
        "id": "ieRNItO2Deug"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AlexNet_Model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGaeC3slDhVf",
        "outputId": "e45c1d77-6c9c-42bf-a6d9-ef3d23b02f35"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AlexNet(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): ReLU(inplace=True)\n",
              "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.5, inplace=False)\n",
              "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Dropout(p=0.5, inplace=False)\n",
              "    (4): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Linear(in_features=1024, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# move the input and model to GPU for speed if available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "JCnnNxUTDx0c"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkK9ShsRD3nD",
        "outputId": "5c05833b-1fbf-43c9-e9bb-1e01bf921924"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "AlexNet_Model.to(device)"
      ],
      "metadata": {
        "id": "5EKdMB0QDkxz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71e9d222-4ddc-4b71-c1ae-81329e15e5b0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AlexNet(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): ReLU(inplace=True)\n",
              "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.5, inplace=False)\n",
              "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Dropout(p=0.5, inplace=False)\n",
              "    (4): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Linear(in_features=1024, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(AlexNet_Model.parameters(), lr=0.001, momentum=0.9)\n"
      ],
      "metadata": {
        "id": "gxSZGTpeFkID"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "metadata": {
        "id": "VkWcUOZ-Fl1X"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(7):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    start_time = time.time()\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        output = AlexNet_Model(inputs)\n",
        "        loss = criterion(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        #Time\n",
        "        end_time = time.time()\n",
        "        time_taken = end_time - start_time\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 2000))\n",
        "            print('Time:',time_taken)\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training of AlexNet')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpJfBbqIFoLp",
        "outputId": "b13f80a7-ad1a-4bec-99cb-9aa4ba3d0bdb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,  2000] loss: 1.221\n",
            "Time: 40.65960431098938\n",
            "[1,  4000] loss: 0.876\n",
            "Time: 74.61349248886108\n",
            "[1,  6000] loss: 0.791\n",
            "Time: 108.52622556686401\n",
            "[1,  8000] loss: 0.728\n",
            "Time: 141.89803099632263\n",
            "[1, 10000] loss: 0.708\n",
            "Time: 176.2108120918274\n",
            "[1, 12000] loss: 0.655\n",
            "Time: 210.65842938423157\n",
            "[2,  2000] loss: 0.508\n",
            "Time: 34.443217277526855\n",
            "[2,  4000] loss: 0.516\n",
            "Time: 68.79577374458313\n",
            "[2,  6000] loss: 0.504\n",
            "Time: 102.18529081344604\n",
            "[2,  8000] loss: 0.512\n",
            "Time: 136.60436630249023\n",
            "[2, 10000] loss: 0.488\n",
            "Time: 171.00564551353455\n",
            "[2, 12000] loss: 0.489\n",
            "Time: 204.4503207206726\n",
            "[3,  2000] loss: 0.354\n",
            "Time: 34.56595158576965\n",
            "[3,  4000] loss: 0.344\n",
            "Time: 68.01108813285828\n",
            "[3,  6000] loss: 0.341\n",
            "Time: 102.29854917526245\n",
            "[3,  8000] loss: 0.366\n",
            "Time: 136.63049006462097\n",
            "[3, 10000] loss: 0.363\n",
            "Time: 170.1482584476471\n",
            "[3, 12000] loss: 0.367\n",
            "Time: 204.56061506271362\n",
            "[4,  2000] loss: 0.232\n",
            "Time: 33.621254444122314\n",
            "[4,  4000] loss: 0.247\n",
            "Time: 67.92758560180664\n",
            "[4,  6000] loss: 0.262\n",
            "Time: 102.59734010696411\n",
            "[4,  8000] loss: 0.267\n",
            "Time: 136.03588128089905\n",
            "[4, 10000] loss: 0.263\n",
            "Time: 170.53085803985596\n",
            "[4, 12000] loss: 0.272\n",
            "Time: 204.95799374580383\n",
            "[5,  2000] loss: 0.175\n",
            "Time: 34.412858724594116\n",
            "[5,  4000] loss: 0.175\n",
            "Time: 68.95922112464905\n",
            "[5,  6000] loss: 0.208\n",
            "Time: 102.49120163917542\n",
            "[5,  8000] loss: 0.199\n",
            "Time: 136.8490126132965\n",
            "[5, 10000] loss: 0.216\n",
            "Time: 171.2168402671814\n",
            "[5, 12000] loss: 0.210\n",
            "Time: 204.6280882358551\n",
            "[6,  2000] loss: 0.117\n",
            "Time: 34.3517804145813\n",
            "[6,  4000] loss: 0.152\n",
            "Time: 67.76660895347595\n",
            "[6,  6000] loss: 0.149\n",
            "Time: 101.94492030143738\n",
            "[6,  8000] loss: 0.177\n",
            "Time: 136.76582527160645\n",
            "[6, 10000] loss: 0.164\n",
            "Time: 171.09715819358826\n",
            "[6, 12000] loss: 0.180\n",
            "Time: 205.17948269844055\n",
            "[7,  2000] loss: 0.098\n",
            "Time: 34.44257164001465\n",
            "[7,  4000] loss: 0.128\n",
            "Time: 68.02269649505615\n",
            "[7,  6000] loss: 0.127\n",
            "Time: 102.52433824539185\n",
            "[7,  8000] loss: 0.159\n",
            "Time: 136.94074296951294\n",
            "[7, 10000] loss: 0.144\n",
            "Time: 170.555340051651\n",
            "[7, 12000] loss: 0.162\n",
            "Time: 205.01450872421265\n",
            "Finished Training of AlexNet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = {'state_dict': AlexNet_Model.state_dict(),\n",
        "              'optimizer' : optimizer.state_dict()}\n",
        "torch.save(checkpoint, '/content/drive/MyDrive/model_checkpoint82.pth')"
      ],
      "metadata": {
        "id": "BL3YvYFmLyk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing Accuracy\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        outputs = AlexNet_Model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %.2f %%' % (100 * correct / total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bijXS_j3LbRA",
        "outputId": "bc697979-696a-4931-a7b7-f881f15a1d64"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 82.53 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(10):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    start_time = time.time()\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        output = AlexNet_Model(inputs)\n",
        "        loss = criterion(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        #Time\n",
        "        end_time = time.time()\n",
        "        time_taken = end_time - start_time\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 2000))\n",
        "            print('Time:',time_taken)\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training of AlexNet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "57qtXIOiMrBC",
        "outputId": "7070267a-5ffc-4e1b-fbff-42c573eb4b7e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,  2000] loss: 0.074\n",
            "Time: 34.88756775856018\n",
            "[1,  4000] loss: 0.117\n",
            "Time: 68.82552289962769\n",
            "[1,  6000] loss: 0.100\n",
            "Time: 103.04843950271606\n",
            "[1,  8000] loss: 0.090\n",
            "Time: 136.62679767608643\n",
            "[1, 10000] loss: 0.125\n",
            "Time: 170.7538924217224\n",
            "[1, 12000] loss: 0.099\n",
            "Time: 205.01677918434143\n",
            "[2,  2000] loss: 0.091\n",
            "Time: 34.38628840446472\n",
            "[2,  4000] loss: 0.092\n",
            "Time: 69.08539605140686\n",
            "[2,  6000] loss: 0.117\n",
            "Time: 102.5721333026886\n",
            "[2,  8000] loss: 0.107\n",
            "Time: 136.97537398338318\n",
            "[2, 10000] loss: 0.095\n",
            "Time: 171.50011825561523\n",
            "[2, 12000] loss: 0.122\n",
            "Time: 204.9225697517395\n",
            "[3,  2000] loss: 0.080\n",
            "Time: 34.40765452384949\n",
            "[3,  4000] loss: 0.084\n",
            "Time: 69.07219076156616\n",
            "[3,  6000] loss: 0.079\n",
            "Time: 104.42134499549866\n",
            "[3,  8000] loss: 0.097\n",
            "Time: 138.96140503883362\n",
            "[3, 10000] loss: 0.094\n",
            "Time: 173.3394296169281\n",
            "[3, 12000] loss: 0.109\n",
            "Time: 207.34182596206665\n",
            "[4,  2000] loss: 0.060\n",
            "Time: 34.53253889083862\n",
            "[4,  4000] loss: 0.078\n",
            "Time: 68.1349356174469\n",
            "[4,  6000] loss: 0.083\n",
            "Time: 102.7536883354187\n",
            "[4,  8000] loss: 0.087\n",
            "Time: 137.01374053955078\n",
            "[4, 10000] loss: 0.094\n",
            "Time: 170.69915628433228\n",
            "[4, 12000] loss: 0.107\n",
            "Time: 205.14063811302185\n",
            "[5,  2000] loss: 0.056\n",
            "Time: 33.74836182594299\n",
            "[5,  4000] loss: 0.073\n",
            "Time: 68.33744025230408\n",
            "[5,  6000] loss: 0.081\n",
            "Time: 102.84843802452087\n",
            "[5,  8000] loss: 0.067\n",
            "Time: 136.26086330413818\n",
            "[5, 10000] loss: 0.055\n",
            "Time: 170.52696013450623\n",
            "[5, 12000] loss: 0.074\n",
            "Time: 204.77123761177063\n",
            "[6,  2000] loss: 0.045\n",
            "Time: 34.20683288574219\n",
            "[6,  4000] loss: 0.055\n",
            "Time: 68.57346987724304\n",
            "[6,  6000] loss: 0.070\n",
            "Time: 102.08412194252014\n",
            "[6,  8000] loss: 0.066\n",
            "Time: 136.50654292106628\n",
            "[6, 10000] loss: 0.081\n",
            "Time: 170.67240595817566\n",
            "[6, 12000] loss: 0.090\n",
            "Time: 203.97444319725037\n",
            "[7,  2000] loss: 0.070\n",
            "Time: 34.15115928649902\n",
            "[7,  4000] loss: 0.065\n",
            "Time: 67.46798491477966\n",
            "[7,  6000] loss: 0.075\n",
            "Time: 101.6580662727356\n",
            "[7,  8000] loss: 0.057\n",
            "Time: 136.01276922225952\n",
            "[7, 10000] loss: 0.090\n",
            "Time: 169.32575178146362\n",
            "[7, 12000] loss: 0.073\n",
            "Time: 203.51834917068481\n",
            "[8,  2000] loss: 0.066\n",
            "Time: 33.35101246833801\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-dccc452e89c0>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# print statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1999\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# print every 2000 mini-batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[%d, %5d] loss: %.3f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing Accuracy\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        outputs = AlexNet_Model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %.2f %%' % (100 * correct / total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzYzqO6-S0th",
        "outputId": "8356dfee-2e03-44c1-9742-1cefb47f06ed"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 83.87 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a65Q5rnUTPy6",
        "outputId": "ffd02d93-5a90-43dc-94a7-7d5a52169698"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = {'state_dict': AlexNet_Model.state_dict(),\n",
        "              'optimizer' : optimizer.state_dict()}\n",
        "torch.save(checkpoint, '/content/drive/MyDrive/model_checkpoint8387.pth')"
      ],
      "metadata": {
        "id": "S-a50pptSvfd"
      },
      "execution_count": 21,
      "outputs": []
    }
  ]
}